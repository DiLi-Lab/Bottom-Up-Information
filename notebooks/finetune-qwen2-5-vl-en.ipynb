{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e058938c",
   "metadata": {},
   "source": [
    "## Finetune QWEN2.5-VL-7B\n",
    "\n",
    "### EN-Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e140c338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 13 20:52:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.107.02             Driver Version: 550.107.02     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090 Ti     On  |   00000000:02:00.0 Off |                  Off |\n",
      "| 30%   24C    P8             35W /  480W |       2MiB /  24564MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090 Ti     On  |   00000000:03:00.0 Off |                  Off |\n",
      "| 30%   24C    P8             27W /  480W |       2MiB /  24564MiB |      0%   E. Process |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01750b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82e313db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Automatically loads .env from the current directory\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "roboflow_api_key = os.getenv(\"ROBOFLOW_API_KEY\")\n",
    "\n",
    "# Optional: Set them in os.environ if downstream libraries expect them there\n",
    "os.environ[\"HF_TOKEN\"] = hf_token\n",
    "os.environ[\"ROBOFLOW_API_KEY\"] = roboflow_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d5d17",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156de060",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "img_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_lower_20250513/labels_train.txt\"\n",
    "# all image names in image_path\n",
    "image_folder = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_lower_20250513/images\"\n",
    "# get the list of all image names in the directory\n",
    "img_list = os.listdir(image_folder)\n",
    "print(f\"Number of images in {image_folder}: {len(img_list)}\")\n",
    "\n",
    "img_csv = pd.read_csv(img_path, sep=\",\")\n",
    "img_dict_train= {}\n",
    "for index, row in img_csv.iterrows():\n",
    "    if row['image_path'] in img_list:\n",
    "        img_dict_train[row['image_path']] = (row['label'], 1) # dummy freq, we don't really need it for val and validation\n",
    "\n",
    "with open(\"/swdata/yin/Cui/EM/reveil/data/en/en-word/lower/img_dict_train.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for key, value in img_dict_train.items():\n",
    "        f.write(json.dumps({'image': key, 'prefix': 'Please identify the English words in the images', 'label': value[0], 'normal_freq': value[1]}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# print the img_dict\n",
    "# print the first 10 items\n",
    "for i, (key, value) in enumerate(img_dict_train.items()):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "en_words_train = list(img_dict_train.keys())\n",
    "len(en_words_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ca7b2",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54294a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test dataset, the img items are also stored in annotation file\n",
    "annotation_path = \"/swdata/yin/Cui/EM/reveil/data/en/en-word/word_freq.csv\"\n",
    "image_folder = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_lower_20250513/images\"\n",
    "# get the list of all image names in the directory\n",
    "img_list = os.listdir(image_folder)\n",
    "print(f\"Number of images in {image_folder}: {len(img_list)}\")\n",
    "\n",
    "annotation_csv = pd.read_csv(annotation_path, sep=\",\")\n",
    "img_dict_test= {}\n",
    "for index, row in annotation_csv.iterrows():\n",
    "    if row['image_path'] in img_list:\n",
    "        img_dict_test[row['image_path']] = (row['label'], row['normal_freq'])\n",
    "\n",
    "with open(\"/swdata/yin/Cui/EM/reveil/data/en/en-word/lower/img_dict_test.json\", \"w\") as f:\n",
    "    # dump to jsonl format\n",
    "    for key, value in img_dict_test.items():\n",
    "        f.write(json.dumps({'image': key, 'prefix': 'Please identify the English words in the images', 'label': value[0], 'normal_freq': value[1]}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "for i, (key, value) in enumerate(img_dict_test.items()):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "en_words_test = list(img_dict_test.keys())\n",
    "len(en_words_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e34a3",
   "metadata": {},
   "source": [
    "### Vali Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_whole_20250513/labels_val.txt\"\n",
    "image_folder = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_whole_20250513/images\"\n",
    "img_list = os.listdir(image_folder)\n",
    "print(f\"Number of images in {image_folder}: {len(img_list)}\")\n",
    "\n",
    "img_csv = pd.read_csv(img_path, sep=\",\")\n",
    "img_dict_val= {}\n",
    "for index, row in img_csv.iterrows():\n",
    "    if row['image_path'] in img_list:\n",
    "        img_dict_val[row['image_path']] = (row['label'], 1) # dummy freq, we don't really need it for val and validation\n",
    "\n",
    "with open(\"/swdata/yin/Cui/EM/reveil/data/en/en-word/whole/img_dict_val.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for key, value in img_dict_val.items():\n",
    "        f.write(json.dumps({'image': key, 'prefix': 'Please identify the English words in the images', 'label': value[0], 'normal_freq': value[1]}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# print the img_dict\n",
    "# print the first 10 items\n",
    "for i, (key, value) in enumerate(img_dict_val.items()):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "en_words_val = list(img_dict_val.keys())\n",
    "len(en_words_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfff5dc",
   "metadata": {},
   "source": [
    "### Format data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b271af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_directory_path = \"/swdata/yin/Cui/EM/reveil/data/en/onestop/en_word_onestop_uniWords_newFont/whole/images\"\n",
    "# image_directory_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_whole_20250513/images\"\n",
    "# SYSTEM_MESSAGE = \"You are a helpful assistant that can identify English words in images. You will be shown an image of a word, and you need to identify the word in the image. Please answer with a single word, and do not include any other text.\"\n",
    "# PROMPT = \"The image contains an English word. What is the word in the image? Please answer with a valid English word, and do not include any other text. The word is:\"\n",
    "\n",
    "\n",
    "# image_directory_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_upper_20250513/images\"\n",
    "# # image_directory_path = \"/swdata/yin/Cui/EM/reveil/data/en/onestop/en_word_onestop_uniWords_newFont/upper/images\"\n",
    "# SYSTEM_MESSAGE = \"You are a helpful assistant that can identify English words in images. The image will show only the upper half of an English word, with the lower half masked. Identify the word accurately based on the visible portion.  Please answer with a single word, and do not include any other text.\"\n",
    "# PROMPT = \"The image contains the upper half of an English word. The lower half is masked. What is the word in the image? Please answer with a single word, and do not include any other text. The word is:\"\n",
    "\n",
    "\n",
    "# image_directory_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_lower_20250513/images\"\n",
    "image_directory_path = \"/swdata/yin/Cui/EM/reveil/data/en/onestop/en_word_onestop_uniWords_newFont/lower/images\"\n",
    "SYSTEM_MESSAGE = \"You are a helpful assistant that can identify English words in images. The image will show only the lower half of an English word, with the upper half masked. Identify the word accurately based on the visible portion.  Please answer with a single word, and do not include any other text.\"\n",
    "PROMPT = \"The image contains the lower half of an English word. The upper half is masked. What is the word in the image? Please answer with a single word, and do not include any other text. The word is:\"\n",
    "\n",
    "\n",
    "def format_data(image_directory_path, entry):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": SYSTEM_MESSAGE}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image_directory_path + \"/\" + entry['image'],\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": PROMPT,\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": entry['label']}],\n",
    "        },\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194feb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class JSONLDataset(Dataset):\n",
    "    def __init__(self, jsonl_file_path: str, image_directory_path: str):\n",
    "        self.jsonl_file_path = jsonl_file_path\n",
    "        self.image_directory_path = image_directory_path\n",
    "        self.entries = self._load_entries()\n",
    "\n",
    "    def _load_entries(self):\n",
    "        entries = []\n",
    "        with open(self.jsonl_file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                data = json.loads(line)\n",
    "                entries.append(data)\n",
    "        # print(entries )\n",
    "        return entries\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if idx < 0 or idx >= len(self.entries):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "        entry = self.entries[idx]\n",
    "        image_path = os.path.join(self.image_directory_path, entry['image'])\n",
    "        image = Image.open(image_path)\n",
    "        return image, entry, format_data(self.image_directory_path, entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b572c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = JSONLDataset(\n",
    "#     jsonl_file_path=\"/swdata/yin/Cui/EM/reveil/data/zh/zh-char/upper/img_dict_train.json\",\n",
    "#     image_directory_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_zh/zh_char_upper_20250512/images\",\n",
    "# )\n",
    "# valid_dataset = JSONLDataset(\n",
    "#     jsonl_file_path = \"/swdata/yin/Cui/EM/reveil/data/zh/zh-char/upper/img_dict_val.json\",\n",
    "#     image_directory_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_zh/zh_char_upper_20250512/images\",\n",
    "# )\n",
    "\n",
    "# test_dataset = JSONLDataset(\n",
    "#     jsonl_file_path = \"/swdata/yin/Cui/EM/reveil/data/en/en-word/whole/img_dict_test.json\",\n",
    "#     image_directory_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_whole_20250513/images\",\n",
    "# )\n",
    "\n",
    "# test_dataset = JSONLDataset(\n",
    "#     jsonl_file_path = \"/swdata/yin/Cui/EM/reveil/data/en/en-word/upper/img_dict_test.json\",\n",
    "#     image_directory_path = \"/swdata/yin/Cui/Re-Veil/create-dataset-new/dataset_en/en_word_upper_20250513/images\",\n",
    "# )\n",
    "\n",
    "test_dataset = JSONLDataset(\n",
    "    jsonl_file_path = \"/swdata/yin/Cui/EM/reveil/data/en/onestop/en_word_onestop_uniWords_newFont/lower/img_dict_test.json\",\n",
    "    image_directory_path = \"/swdata/yin/Cui/EM/reveil/data/en/onestop/en_word_onestop_uniWords_newFont/lower/images\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b83613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = [test_dataset[i] for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69a4c3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=95x50>,\n",
       " {'image': '0.jpg',\n",
       "  'prefix': 'Please identify the English words in the images',\n",
       "  'label': 'Year',\n",
       "  'normal_freq': 0.0012620344886189},\n",
       " [{'role': 'system',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'You are a helpful assistant that can identify English words in images. The image will show only the lower half of an English word, with the upper half masked. Identify the word accurately based on the visible portion.  Please answer with a single word, and do not include any other text.'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'image',\n",
       "     'image': '/swdata/yin/Cui/EM/reveil/data/en/onestop/en_word_onestop_uniWords_newFont/lower/images/0.jpg'},\n",
       "    {'type': 'text',\n",
       "     'text': 'The image contains the lower half of an English word. The upper half is masked. What is the word in the image? Please answer with a single word, and do not include any other text. The word is:'}]},\n",
       "  {'role': 'assistant', 'content': [{'type': 'text', 'text': 'Year'}]}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c838fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=95x50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6280b",
   "metadata": {},
   "source": [
    "## Zero-Shot Qwen2.5-VL-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df7e1e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/swdata/yin/miniconda3/envs/reveil/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from maestro.trainer.models.qwen_2_5_vl.checkpoints import load_model, OptimizationStrategy\n",
    "\n",
    "MODEL_ID_OR_PATH = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "# MODEL_ID_OR_PATH = \"Qwen/Qwen2.5-VL-72B-Instruct\"\n",
    "MIN_PIXELS = 28 * 28\n",
    "MAX_PIXELS = 1028 * 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c68b2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [02:49<00:00, 33.80s/it]\n"
     ]
    }
   ],
   "source": [
    "processor, model = load_model(\n",
    "    model_id_or_path=MODEL_ID_OR_PATH,\n",
    "    optimization_strategy=OptimizationStrategy.NONE,\n",
    "    min_pixels=MIN_PIXELS,\n",
    "    max_pixels=MAX_PIXELS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c678f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, Qwen2_5_VLProcessor\n",
    "\n",
    "from maestro.trainer.common.utils.device import parse_device_spec\n",
    "from maestro.trainer.models.qwen_2_5_vl.loaders import format_conversation\n",
    "\n",
    "def predict_score_with_inputs(\n",
    "    model: Qwen2_5_VLForConditionalGeneration,\n",
    "    processor: Qwen2_5_VLProcessor,\n",
    "    input_ids: torch.Tensor,\n",
    "    attention_mask: torch.Tensor,\n",
    "    pixel_values: torch.Tensor,\n",
    "    image_grid_thw: torch.Tensor,\n",
    "    device: torch.device,\n",
    "    max_new_tokens: int = 1024,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Generates predictions from the Qwen2.5-VL model using both textual and visual inputs.\n",
    "\n",
    "    Args:\n",
    "        model (Qwen2_5_VLForConditionalGeneration):\n",
    "            A Qwen2.5-VL model capable of conditional text generation with visual context.\n",
    "        processor (Qwen2_5_VLProcessor):\n",
    "            Preprocessing and postprocessing utility for the Qwen2.5-VL model.\n",
    "        input_ids (torch.Tensor):\n",
    "            Tokenized input text IDs.\n",
    "        attention_mask (torch.Tensor):\n",
    "            Attention mask corresponding to the tokenized input.\n",
    "        pixel_values (torch.Tensor):\n",
    "            Preprocessed image data (pixel values) for visual inputs.\n",
    "        image_grid_thw (torch.Tensor):\n",
    "            Tensor specifying the layout or shape of the provided images.\n",
    "        device (torch.device):\n",
    "            Device on which to run inference (e.g., ``torch.device(\"cuda\")`` or ``torch.device(\"cpu\")``).\n",
    "        max_new_tokens (int):\n",
    "            Maximum number of tokens to generate.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of decoded strings corresponding to the generated sequences.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids.to(device),\n",
    "            attention_mask=attention_mask.to(device),\n",
    "            pixel_values=pixel_values.to(device),\n",
    "            image_grid_thw=image_grid_thw.to(device),\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            output_scores=True,\n",
    "            return_dict_in_generate=True,\n",
    "            do_sample=False,  # Non-greedy decoding\n",
    "        )\n",
    "        generated_ids = [\n",
    "            generated_sequence[len(input_sequence) :]\n",
    "            for input_sequence, generated_sequence in zip(input_ids, outputs.sequences)\n",
    "        ]\n",
    "        return processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False), outputs.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257afecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from typing import Optional, Tuple, Union\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from maestro.trainer.models.qwen_2_5_vl.inference import predict_with_inputs\n",
    "from maestro.trainer.models.qwen_2_5_vl.loaders import format_conversation\n",
    "from maestro.trainer.common.utils.device import parse_device_spec\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def run_qwen_2_5_vl_inference(\n",
    "    model,\n",
    "    processor,\n",
    "    conversation: Union[str, dict],\n",
    "    target_token: str = \"a\",\n",
    "    device: str = \"auto\",\n",
    "    max_new_tokens: int = 1024,\n",
    ") -> Tuple[str, Tuple[int, int]]:\n",
    "    device = parse_device_spec(device)\n",
    "    text = processor.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, _ = process_vision_info(conversation)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=text,\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    responses, scores = predict_score_with_inputs(\n",
    "        **inputs,\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        device=device,\n",
    "        max_new_tokens=max_new_tokens\n",
    "    )\n",
    "    response = responses[0]\n",
    "\n",
    "    logits = scores[0][0]\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    target_token_tokenized = processor.tokenizer.tokenize(target_token) \n",
    "    target_token_id = processor.tokenizer.convert_tokens_to_ids(target_token_tokenized[0])  # a few target tokens will have multiple subtokens\n",
    "    prob_target = probs[target_token_id].item()\n",
    "\n",
    "    # Entropy of the distribution\n",
    "    entropy = -(probs * probs.log()).sum().item()\n",
    "\n",
    "    # Top-5 predictions with probabilities and logits\n",
    "    topk_probs, topk_ids = torch.topk(probs, k=5)\n",
    "    topk_tokens = [processor.tokenizer.decode([idx]).strip() for idx in topk_ids]\n",
    "    top5 = [\n",
    "        {\"token\": tok, \"prob\": prob.item(), \"logit\": logits[idx].item()}\n",
    "        for tok, prob, idx in zip(topk_tokens, topk_probs, topk_ids)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"target\": target_token,\n",
    "        \"prob_target\": prob_target,\n",
    "        \"entropy\": entropy,\n",
    "        \"top5\": top5\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1e-06` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target_Char: Year, Response: real\n",
      "Entropy: 1.3188, Cumulative Entropy: 1.3188, Surprisal: 9.0606\n",
      "Target_Char: Old, Response: old\n",
      "Entropy: 2.2572, Cumulative Entropy: 3.5760, Surprisal: 1.0350\n",
      "Target_Char: Bottle, Response: Doll\n",
      "Entropy: 4.7398, Cumulative Entropy: 8.3158, Surprisal: 1.7658\n",
      "Target_Char: Message, Response: Message\n",
      "Entropy: 1.4914, Cumulative Entropy: 9.8071, Surprisal: 0.6506\n",
      "Target_Char: Angela, Response: Anglia\n",
      "Entropy: 5.4341, Cumulative Entropy: 15.2412, Surprisal: 1.2897\n",
      "Target_Char: Erdmann, Response: Library\n",
      "Entropy: 5.5894, Cumulative Entropy: 20.8306, Surprisal: 5.3435\n",
      "Target_Char: never, Response: level\n",
      "Entropy: 5.8906, Cumulative Entropy: 26.7212, Surprisal: 3.6296\n",
      "Target_Char: knew, Response: know\n",
      "Entropy: 3.0663, Cumulative Entropy: 29.7874, Surprisal: 1.9262\n",
      "Target_Char: her, Response: HAT\n",
      "Entropy: 6.8225, Cumulative Entropy: 36.6100, Surprisal: 7.8168\n",
      "Target_Char: grandfather, Response: grandfather\n",
      "Entropy: 2.7861, Cumulative Entropy: 39.3960, Surprisal: 0.6254\n",
      "Target_Char: He, Response: nice\n",
      "Entropy: 6.3551, Cumulative Entropy: 45.7511, Surprisal: 7.3278\n",
      "Target_Char: died, Response: idea\n",
      "Entropy: 1.3587, Cumulative Entropy: 47.1097, Surprisal: 6.7266\n",
      "Target_Char: in, Response: TALL\n",
      "Entropy: 6.7608, Cumulative Entropy: 53.8706, Surprisal: 6.6764\n",
      "Target_Char: six, Response: DIA\n",
      "Entropy: 4.7074, Cumulative Entropy: 58.5779, Surprisal: 8.9306\n",
      "Target_Char: years, Response: years\n",
      "Entropy: 0.6214, Cumulative Entropy: 59.1994, Surprisal: 0.0804\n",
      "Target_Char: before, Response: picture\n",
      "Entropy: 6.3931, Cumulative Entropy: 65.5924, Surprisal: 4.8274\n",
      "Target_Char: she, Response: ONE\n",
      "Entropy: 6.1479, Cumulative Entropy: 71.7403, Surprisal: 6.4814\n",
      "Target_Char: was, Response: was\n",
      "Entropy: 1.6622, Cumulative Entropy: 73.4025, Surprisal: 0.2588\n",
      "Target_Char: born, Response: DOUNT\n",
      "Entropy: 6.0414, Cumulative Entropy: 79.4439, Surprisal: 8.5718\n",
      "Target_Char: But, Response: But\n",
      "Entropy: 3.2665, Cumulative Entropy: 82.7104, Surprisal: 1.1029\n",
      "Target_Char: on, Response: OFF\n",
      "Entropy: 6.8395, Cumulative Entropy: 89.5499, Surprisal: 4.3455\n",
      "Target_Char: Tuesday, Response: Tuesday\n",
      "Entropy: 0.5155, Cumulative Entropy: 90.0654, Surprisal: 0.0799\n",
      "Target_Char: April, Response: April\n",
      "Entropy: 1.4106, Cumulative Entropy: 91.4760, Surprisal: 0.1632\n",
      "Target_Char: described, Response: describe\n",
      "Entropy: 1.7769, Cumulative Entropy: 93.2529, Surprisal: 1.9882\n",
      "Target_Char: the, Response: line\n",
      "Entropy: 5.7949, Cumulative Entropy: 99.0478, Surprisal: 7.0074\n",
      "Target_Char: extraordinary, Response: extraordinary\n",
      "Entropy: 1.1707, Cumulative Entropy: 100.2186, Surprisal: 0.3477\n",
      "Target_Char: moment, Response: moment\n",
      "Entropy: 2.5621, Cumulative Entropy: 102.7806, Surprisal: 0.6431\n",
      "Target_Char: when, Response: which\n",
      "Entropy: 1.7174, Cumulative Entropy: 104.4980, Surprisal: 2.4569\n",
      "Target_Char: received, Response: received\n",
      "Entropy: 1.8185, Cumulative Entropy: 106.3166, Surprisal: 0.3270\n",
      "Target_Char: a, Response: cat\n",
      "Entropy: 4.3276, Cumulative Entropy: 110.6441, Surprisal: 2.8342\n",
      "Target_Char: message, Response: message\n",
      "Entropy: 1.5163, Cumulative Entropy: 112.1605, Surprisal: 0.3270\n",
      "Target_Char: bottle, Response: Bottle\n",
      "Entropy: 4.6212, Cumulative Entropy: 116.7816, Surprisal: 1.6539\n",
      "Target_Char: after, Response: alter\n",
      "Entropy: 4.4757, Cumulative Entropy: 121.2574, Surprisal: 2.4809\n",
      "Target_Char: he, Response: HAT\n",
      "Entropy: 6.5620, Cumulative Entropy: 127.8193, Surprisal: 6.5213\n",
      "Target_Char: had, Response: train\n",
      "Entropy: 5.3012, Cumulative Entropy: 133.1205, Surprisal: 6.6683\n",
      "Target_Char: lobbed, Response: London\n",
      "Entropy: 5.7156, Cumulative Entropy: 138.8361, Surprisal: 6.8279\n",
      "Target_Char: it, Response: ILLNESS\n",
      "Entropy: 4.8125, Cumulative Entropy: 143.6486, Surprisal: 6.8919\n",
      "Target_Char: into, Response: hello\n",
      "Entropy: 5.5740, Cumulative Entropy: 149.2226, Surprisal: 5.8818\n",
      "Target_Char: Baltic, Response: Battle\n",
      "Entropy: 3.4413, Cumulative Entropy: 152.6639, Surprisal: 2.3631\n",
      "Target_Char: Sea, Response: cat\n",
      "Entropy: 5.8311, Cumulative Entropy: 158.4950, Surprisal: 4.5822\n",
      "Target_Char: Thought, Response: thought\n",
      "Entropy: 0.9929, Cumulative Entropy: 159.4878, Surprisal: 2.5927\n",
      "Target_Char: to, Response: LOVE\n",
      "Entropy: 5.8151, Cumulative Entropy: 165.3029, Surprisal: 4.9829\n",
      "Target_Char: be, Response: be\n",
      "Entropy: 5.9422, Cumulative Entropy: 171.2451, Surprisal: 2.1025\n",
      "Target_Char: world, Response: world\n",
      "Entropy: 1.2762, Cumulative Entropy: 172.5214, Surprisal: 0.3203\n",
      "Target_Char: s, Response: COPPER\n",
      "Entropy: 5.5114, Cumulative Entropy: 178.0328, Surprisal: 5.8062\n",
      "Target_Char: oldest, Response: oldest\n",
      "Entropy: 2.5269, Cumulative Entropy: 180.5597, Surprisal: 0.4057\n",
      "Target_Char: presented, Response: presented\n",
      "Entropy: 2.1832, Cumulative Entropy: 182.7429, Surprisal: 0.4547\n",
      "Target_Char: by, Response: buy\n",
      "Entropy: 4.3974, Cumulative Entropy: 187.1403, Surprisal: 4.0273\n",
      "Target_Char: museum, Response: Museum\n",
      "Entropy: 2.0470, Cumulative Entropy: 189.1873, Surprisal: 0.8562\n",
      "Target_Char: that, Response: ideal\n",
      "Entropy: 5.4213, Cumulative Entropy: 194.6085, Surprisal: 7.7816\n",
      "Target_Char: is, Response: dog\n",
      "Entropy: 6.2471, Cumulative Entropy: 200.8556, Surprisal: 4.9801\n",
      "Target_Char: now, Response: flow\n",
      "Entropy: 3.4721, Cumulative Entropy: 204.3277, Surprisal: 2.8255\n",
      "Target_Char: exhibiting, Response: campaigning\n",
      "Entropy: 4.8693, Cumulative Entropy: 209.1969, Surprisal: 6.8007\n",
      "Target_Char: Germany, Response: Germany\n",
      "Entropy: 1.1907, Cumulative Entropy: 210.3876, Surprisal: 0.1804\n",
      "Target_Char: It, Response: ALL\n",
      "Entropy: 6.2823, Cumulative Entropy: 216.6699, Surprisal: 8.9145\n",
      "Target_Char: very, Response: very\n",
      "Entropy: 1.4456, Cumulative Entropy: 218.1155, Surprisal: 0.1957\n",
      "Target_Char: surprising, Response: surprising\n",
      "Entropy: 1.8348, Cumulative Entropy: 219.9503, Surprisal: 0.3014\n",
      "Target_Char: said, Response: save\n",
      "Entropy: 5.3502, Cumulative Entropy: 225.3005, Surprisal: 4.5377\n",
      "Target_Char: recalling, Response: recalling\n",
      "Entropy: 1.8441, Cumulative Entropy: 227.1446, Surprisal: 0.3592\n",
      "Target_Char: how, Response: NOW\n",
      "Entropy: 3.4867, Cumulative Entropy: 230.6314, Surprisal: 3.3180\n",
      "Target_Char: found, Response: round\n",
      "Entropy: 2.2234, Cumulative Entropy: 232.8548, Surprisal: 4.7067\n",
      "Target_Char: out, Response: out\n",
      "Entropy: 1.7503, Cumulative Entropy: 234.6051, Surprisal: 0.3272\n",
      "Target_Char: about, Response: about\n",
      "Entropy: 0.3880, Cumulative Entropy: 234.9932, Surprisal: 0.0613\n",
      "Target_Char: A, Response: hat\n",
      "Entropy: 6.2165, Cumulative Entropy: 241.2096, Surprisal: 4.2693\n",
      "Target_Char: man, Response: man\n",
      "Entropy: 5.7296, Cumulative Entropy: 246.9392, Surprisal: 2.7503\n",
      "Target_Char: stood, Response: stood\n",
      "Entropy: 1.7695, Cumulative Entropy: 248.7087, Surprisal: 0.3794\n",
      "Target_Char: at, Response: cat\n",
      "Entropy: 4.5118, Cumulative Entropy: 253.2206, Surprisal: 4.7907\n",
      "Target_Char: my, Response: sky\n",
      "Entropy: 5.7989, Cumulative Entropy: 259.0195, Surprisal: 5.2360\n",
      "Target_Char: door, Response: door\n",
      "Entropy: 1.8491, Cumulative Entropy: 260.8685, Surprisal: 0.3779\n",
      "Target_Char: and, Response: area\n",
      "Entropy: 5.1278, Cumulative Entropy: 265.9963, Surprisal: 4.8200\n",
      "Target_Char: told, Response: total\n",
      "Entropy: 5.7603, Cumulative Entropy: 271.7566, Surprisal: 2.8927\n",
      "Target_Char: me, Response: MAGNETIC\n",
      "Entropy: 6.8018, Cumulative Entropy: 278.5584, Surprisal: 6.5479\n",
      "Target_Char: post, Response: post\n",
      "Entropy: 1.8068, Cumulative Entropy: 280.3651, Surprisal: 0.3492\n",
      "Target_Char: from, Response: HOME\n",
      "Entropy: 4.5811, Cumulative Entropy: 284.9463, Surprisal: 4.7537\n",
      "Target_Char: then, Response: light\n",
      "Entropy: 1.2930, Cumulative Entropy: 286.2393, Surprisal: 12.3015\n",
      "Target_Char: been, Response: DEEP\n",
      "Entropy: 5.2802, Cumulative Entropy: 291.5195, Surprisal: 3.8055\n",
      "Target_Char: name, Response: name\n",
      "Entropy: 2.6324, Cumulative Entropy: 294.1519, Surprisal: 0.5118\n",
      "Target_Char: card, Response: card\n",
      "Entropy: 3.3614, Cumulative Entropy: 297.5133, Surprisal: 1.3915\n",
      "Target_Char: of, Response: potato\n",
      "Entropy: 6.4715, Cumulative Entropy: 303.9847, Surprisal: 5.3742\n",
      "Target_Char: Her, Response: HAPPY\n",
      "Entropy: 7.1136, Cumulative Entropy: 311.0983, Surprisal: 8.0562\n",
      "Target_Char: visitor, Response: visitor\n",
      "Entropy: 3.5811, Cumulative Entropy: 314.6795, Surprisal: 1.4137\n",
      "Target_Char: genealogical, Response: genealogical\n",
      "Entropy: 1.5508, Cumulative Entropy: 316.2302, Surprisal: 0.6099\n",
      "Target_Char: researcher, Response: researcher\n",
      "Entropy: 1.7057, Cumulative Entropy: 317.9359, Surprisal: 0.4021\n",
      "Target_Char: who, Response: who\n",
      "Entropy: 2.8926, Cumulative Entropy: 320.8286, Surprisal: 1.0989\n",
      "Target_Char: managed, Response: manager\n",
      "Entropy: 3.1966, Cumulative Entropy: 324.0251, Surprisal: 5.3490\n",
      "Target_Char: track, Response: track\n",
      "Entropy: 1.0191, Cumulative Entropy: 325.0442, Surprisal: 0.1759\n",
      "Target_Char: down, Response: down\n",
      "Entropy: 2.8205, Cumulative Entropy: 327.8647, Surprisal: 0.5355\n",
      "Target_Char: Berlin, Response: Berlin\n",
      "Entropy: 3.5977, Cumulative Entropy: 331.4624, Surprisal: 0.7657\n",
      "Target_Char: letter, Response: hello\n",
      "Entropy: 6.9543, Cumulative Entropy: 338.4168, Surprisal: 6.3812\n",
      "Target_Char: given, Response: given\n",
      "Entropy: 2.3399, Cumulative Entropy: 340.7567, Surprisal: 0.3901\n",
      "Target_Char: International, Response: International\n",
      "Entropy: 3.0286, Cumulative Entropy: 343.7853, Surprisal: 0.6510\n",
      "Target_Char: Maritime, Response: Maritime\n",
      "Entropy: 4.9014, Cumulative Entropy: 348.6867, Surprisal: 2.1245\n",
      "Target_Char: Museum, Response: Museum\n",
      "Entropy: 1.6086, Cumulative Entropy: 350.2953, Surprisal: 0.3712\n",
      "Target_Char: northern, Response: Northern\n",
      "Entropy: 4.1417, Cumulative Entropy: 354.4369, Surprisal: 3.7666\n",
      "Target_Char: port, Response: port\n",
      "Entropy: 2.6947, Cumulative Entropy: 357.1316, Surprisal: 0.6894\n",
      "Target_Char: city, Response: City\n",
      "Entropy: 1.2549, Cumulative Entropy: 358.3866, Surprisal: 2.5769\n",
      "Target_Char: Hamburg, Response: Hamburg\n",
      "Entropy: 1.4393, Cumulative Entropy: 359.8259, Surprisal: 0.2946\n",
      "Target_Char: The, Response: line\n",
      "Entropy: 6.2664, Cumulative Entropy: 366.0923, Surprisal: 7.1532\n",
      "Target_Char: brown, Response: BOWTIE\n",
      "Entropy: 4.6989, Cumulative Entropy: 370.7912, Surprisal: 2.9417\n",
      "Target_Char: beer, Response: DECI\n",
      "Entropy: 6.3942, Cumulative Entropy: 377.1854, Surprisal: 5.7735\n",
      "Target_Char: which, Response: which\n",
      "Entropy: 1.4246, Cumulative Entropy: 378.6100, Surprisal: 0.2968\n",
      "Target_Char: water, Response: water\n",
      "Entropy: 3.7912, Cumulative Entropy: 382.4011, Surprisal: 1.6770\n",
      "Target_Char: for, Response: HOT\n",
      "Entropy: 6.5999, Cumulative Entropy: 389.0010, Surprisal: 4.4608\n",
      "Target_Char: catch, Response: catch\n",
      "Entropy: 1.7378, Cumulative Entropy: 390.7388, Surprisal: 0.2652\n",
      "Target_Char: Konrad, Response: KOMAD\n",
      "Entropy: 5.2113, Cumulative Entropy: 395.9501, Surprisal: 4.0441\n",
      "Target_Char: Fischer, Response: TOSCANI\n",
      "Entropy: 7.4161, Cumulative Entropy: 403.3662, Surprisal: 4.0868\n",
      "Target_Char: fisherman, Response: fisherman\n",
      "Entropy: 5.5659, Cumulative Entropy: 408.9321, Surprisal: 1.4701\n",
      "Target_Char: off, Response: sun\n",
      "Entropy: 6.7286, Cumulative Entropy: 415.6607, Surprisal: 4.9391\n",
      "Target_Char: Kiel, Response: KICK\n",
      "Entropy: 4.6384, Cumulative Entropy: 420.2991, Surprisal: 1.5598\n",
      "Target_Char: Holger, Response: mugger\n",
      "Entropy: 6.7807, Cumulative Entropy: 427.0799, Surprisal: 5.5590\n",
      "Target_Char: von, Response: void\n",
      "Entropy: 2.4556, Cumulative Entropy: 429.5354, Surprisal: 9.2234\n",
      "Target_Char: Neuhoff, Response: Neutron\n",
      "Entropy: 3.7372, Cumulative Entropy: 433.2726, Surprisal: 0.9180\n",
      "Target_Char: curator, Response: curator\n",
      "Entropy: 2.8054, Cumulative Entropy: 436.0780, Surprisal: 0.9089\n",
      "Target_Char: ocean, Response: ocean\n",
      "Entropy: 1.6176, Cumulative Entropy: 437.6956, Surprisal: 0.8477\n",
      "Target_Char: science, Response: science\n",
      "Entropy: 2.3814, Cumulative Entropy: 440.0770, Surprisal: 0.9894\n",
      "Target_Char: this, Response: light\n",
      "Entropy: 7.1928, Cumulative Entropy: 447.2698, Surprisal: 7.6616\n",
      "Target_Char: bottled, Response: POLICE\n",
      "Entropy: 5.6191, Cumulative Entropy: 452.8889, Surprisal: 3.6518\n",
      "Target_Char: come, Response: come\n",
      "Entropy: 2.2217, Cumulative Entropy: 455.1106, Surprisal: 0.6575\n",
      "Target_Char: across, Response: across\n",
      "Entropy: 1.2443, Cumulative Entropy: 456.3549, Surprisal: 0.3156\n",
      "Target_Char: There, Response: there\n",
      "Entropy: 4.2185, Cumulative Entropy: 460.5734, Surprisal: 3.3728\n",
      "Target_Char: are, Response: art\n",
      "Entropy: 2.5933, Cumulative Entropy: 463.1667, Surprisal: 4.7409\n",
      "Target_Char: documents, Response: documents\n",
      "Entropy: 0.8125, Cumulative Entropy: 463.9792, Surprisal: 0.1165\n",
      "Target_Char: have, Response: have\n",
      "Entropy: 0.7636, Cumulative Entropy: 464.7427, Surprisal: 0.1013\n",
      "Target_Char: without, Response: without\n",
      "Entropy: 1.8926, Cumulative Entropy: 466.6354, Surprisal: 0.4840\n",
      "Target_Char: older, Response: older\n",
      "Entropy: 4.4276, Cumulative Entropy: 471.0630, Surprisal: 0.8576\n",
      "Target_Char: with, Response: VILLAGE\n",
      "Entropy: 5.3290, Cumulative Entropy: 476.3920, Surprisal: 9.0737\n",
      "Target_Char: document, Response: document\n",
      "Entropy: 0.9039, Cumulative Entropy: 477.2959, Surprisal: 0.1340\n",
      "Target_Char: certainly, Response: certainly\n",
      "Entropy: 2.2636, Cumulative Entropy: 479.5595, Surprisal: 0.8537\n",
      "Target_Char: extremely, Response: calmly\n",
      "Entropy: 6.2490, Cumulative Entropy: 485.8085, Surprisal: 2.8537\n",
      "Target_Char: good, Response: good\n",
      "Entropy: 2.5726, Cumulative Entropy: 488.3811, Surprisal: 0.6636\n",
      "Target_Char: condition, Response: condition\n",
      "Entropy: 1.8222, Cumulative Entropy: 490.2033, Surprisal: 0.3303\n",
      "Target_Char: Researchers, Response: researchers\n",
      "Entropy: 2.7745, Cumulative Entropy: 492.9778, Surprisal: 2.3506\n",
      "Target_Char: believe, Response: believe\n",
      "Entropy: 1.6143, Cumulative Entropy: 494.5921, Surprisal: 0.7817\n",
      "Target_Char: Richard, Response: Richard\n",
      "Entropy: 1.8971, Cumulative Entropy: 496.4891, Surprisal: 0.2598\n",
      "Target_Char: Platz, Response: ratz\n",
      "Entropy: 6.7372, Cumulative Entropy: 503.2263, Surprisal: 8.0062\n",
      "Target_Char: threw, Response: VIEW\n",
      "Entropy: 6.1550, Cumulative Entropy: 509.3813, Surprisal: 6.8948\n",
      "Target_Char: sea, Response: sea\n",
      "Entropy: 2.3600, Cumulative Entropy: 511.7414, Surprisal: 0.5350\n",
      "Target_Char: while, Response: write\n",
      "Entropy: 3.6983, Cumulative Entropy: 515.4396, Surprisal: 4.2983\n",
      "Target_Char: hike, Response: TIME\n",
      "Entropy: 4.0970, Cumulative Entropy: 519.5366, Surprisal: 6.1565\n",
      "Target_Char: nature, Response: nature\n",
      "Entropy: 1.7815, Cumulative Entropy: 521.3181, Surprisal: 0.6991\n",
      "Target_Char: appreciation, Response: appreciation\n",
      "Entropy: 1.3141, Cumulative Entropy: 522.6322, Surprisal: 0.3430\n",
      "Target_Char: group, Response: group\n",
      "Entropy: 1.4876, Cumulative Entropy: 524.1198, Surprisal: 0.4007\n",
      "Target_Char: old, Response: old\n",
      "Entropy: 6.6481, Cumulative Entropy: 530.7680, Surprisal: 2.7890\n",
      "Target_Char: time, Response: little\n",
      "Entropy: 3.4164, Cumulative Entropy: 534.1843, Surprisal: 4.1449\n",
      "Target_Char: Much, Response: much\n",
      "Entropy: 1.7975, Cumulative Entropy: 535.9818, Surprisal: 1.2564\n",
      "Target_Char: postcard, Response: postcard\n",
      "Entropy: 1.7831, Cumulative Entropy: 537.7649, Surprisal: 0.4417\n",
      "Target_Char: indecipherable, Response: indecipherable\n",
      "Entropy: 2.2011, Cumulative Entropy: 539.9660, Surprisal: 0.5503\n",
      "Target_Char: although, Response: although\n",
      "Entropy: 0.3814, Cumulative Entropy: 540.3474, Surprisal: 0.0547\n",
      "Target_Char: address, Response: address\n",
      "Entropy: 1.2159, Cumulative Entropy: 541.5632, Surprisal: 0.2185\n",
      "Target_Char: front, Response: hotel\n",
      "Entropy: 4.8047, Cumulative Entropy: 546.3679, Surprisal: 8.8127\n",
      "Target_Char: legible, Response: logic\n",
      "Entropy: 2.7316, Cumulative Entropy: 549.0995, Surprisal: 4.2793\n",
      "Target_Char: as, Response: cat\n",
      "Entropy: 5.2238, Cumulative Entropy: 554.3233, Surprisal: 3.3765\n",
      "Target_Char: author, Response: author\n",
      "Entropy: 0.8330, Cumulative Entropy: 555.1563, Surprisal: 0.0988\n",
      "Target_Char: polite, Response: point\n",
      "Entropy: 2.6636, Cumulative Entropy: 557.8199, Surprisal: 2.3945\n",
      "Target_Char: request, Response: request\n",
      "Entropy: 1.3948, Cumulative Entropy: 559.2146, Surprisal: 0.2153\n",
      "Target_Char: note, Response: note\n",
      "Entropy: 2.8464, Cumulative Entropy: 562.0610, Surprisal: 1.1382\n",
      "Target_Char: sent, Response: SOIL\n",
      "Entropy: 6.4603, Cumulative Entropy: 568.5214, Surprisal: 6.8951\n",
      "Target_Char: finder, Response: finder\n",
      "Entropy: 4.3493, Cumulative Entropy: 572.8707, Surprisal: 1.0647\n",
      "Target_Char: his, Response: one\n",
      "Entropy: 6.6568, Cumulative Entropy: 579.5275, Surprisal: 8.2488\n",
      "Target_Char: home, Response: HOME\n",
      "Entropy: 2.1460, Cumulative Entropy: 581.6735, Surprisal: 1.1286\n",
      "Target_Char: also, Response: also\n",
      "Entropy: 0.3443, Cumulative Entropy: 582.0178, Surprisal: 0.0346\n",
      "Target_Char: included, Response: included\n",
      "Entropy: 0.6865, Cumulative Entropy: 582.7043, Surprisal: 0.1143\n",
      "Target_Char: two, Response: love\n",
      "Entropy: 3.3904, Cumulative Entropy: 586.0947, Surprisal: 9.6037\n",
      "Target_Char: stamps, Response: stamps\n",
      "Entropy: 2.5565, Cumulative Entropy: 588.6513, Surprisal: 0.7538\n",
      "Target_Char: were, Response: voice\n",
      "Entropy: 4.6994, Cumulative Entropy: 593.3507, Surprisal: 4.8596\n",
      "Target_Char: so, Response: GO\n",
      "Entropy: 6.2318, Cumulative Entropy: 599.5825, Surprisal: 3.7712\n",
      "Target_Char: would, Response: would\n",
      "Entropy: 1.1413, Cumulative Entropy: 600.7238, Surprisal: 0.1975\n",
      "Target_Char: not, Response: HOLY\n",
      "Entropy: 4.9560, Cumulative Entropy: 605.6798, Surprisal: 2.7582\n",
      "Target_Char: incur, Response: incur\n",
      "Entropy: 6.1430, Cumulative Entropy: 611.8228, Surprisal: 2.4204\n",
      "Target_Char: cost, Response: cost\n",
      "Entropy: 3.0974, Cumulative Entropy: 614.9202, Surprisal: 1.0957\n",
      "Target_Char: did, Response: aid\n",
      "Entropy: 6.2446, Cumulative Entropy: 621.1648, Surprisal: 4.9605\n",
      "Target_Char: think, Response: CINEMA\n",
      "Entropy: 6.7816, Cumulative Entropy: 627.9464, Surprisal: 7.8028\n",
      "Target_Char: take, Response: lane\n",
      "Entropy: 4.7977, Cumulative Entropy: 632.7440, Surprisal: 8.1215\n",
      "Target_Char: She, Response: ONE\n",
      "Entropy: 2.1689, Cumulative Entropy: 634.9129, Surprisal: 9.3224\n",
      "Target_Char: moved, Response: move\n",
      "Entropy: 4.7849, Cumulative Entropy: 639.6978, Surprisal: 2.4924\n",
      "Target_Char: arrival, Response: arrival\n",
      "Entropy: 2.1500, Cumulative Entropy: 641.8478, Surprisal: 0.4047\n",
      "Target_Char: known, Response: know\n",
      "Entropy: 2.9054, Cumulative Entropy: 644.7531, Surprisal: 1.6104\n",
      "Target_Char: because, Response: because\n",
      "Entropy: 1.1063, Cumulative Entropy: 645.8595, Surprisal: 0.2542\n",
      "Target_Char: age, Response: age\n",
      "Entropy: 1.8491, Cumulative Entropy: 647.7086, Surprisal: 0.2759\n",
      "Target_Char: I, Response: up\n",
      "Entropy: 5.8664, Cumulative Entropy: 653.5750, Surprisal: 3.4666\n",
      "Target_Char: little, Response: LILLICIOUS\n",
      "Entropy: 6.4881, Cumulative Entropy: 660.0631, Surprisal: 2.8769\n",
      "Target_Char: but, Response: but\n",
      "Entropy: 2.7503, Cumulative Entropy: 662.8134, Surprisal: 0.4901\n",
      "Target_Char: writer, Response: WINTER\n",
      "Entropy: 4.6205, Cumulative Entropy: 667.4339, Surprisal: 6.7182\n",
      "Target_Char: open, Response: open\n",
      "Entropy: 1.0155, Cumulative Entropy: 668.4494, Surprisal: 0.1839\n",
      "Target_Char: minded, Response: imaged\n",
      "Entropy: 6.2920, Cumulative Entropy: 674.7415, Surprisal: 3.6032\n",
      "Target_Char: believed, Response: believed\n",
      "Entropy: 0.8654, Cumulative Entropy: 675.6069, Surprisal: 0.1520\n",
      "Target_Char: freedom, Response: freedom\n",
      "Entropy: 2.4778, Cumulative Entropy: 678.0846, Surprisal: 0.5421\n",
      "Target_Char: everyone, Response: everyone\n",
      "Entropy: 1.9743, Cumulative Entropy: 680.0589, Surprisal: 0.4157\n",
      "Target_Char: should, Response: shoulda\n",
      "Entropy: 3.1264, Cumulative Entropy: 683.1853, Surprisal: 0.7766\n",
      "Target_Char: respect, Response: Respect\n",
      "Entropy: 2.4543, Cumulative Entropy: 685.6396, Surprisal: 1.5435\n",
      "Target_Char: each, Response: catch\n",
      "Entropy: 2.5540, Cumulative Entropy: 688.1936, Surprisal: 1.0609\n",
      "Target_Char: other, Response: Office\n",
      "Entropy: 6.9316, Cumulative Entropy: 695.1252, Surprisal: 5.7497\n",
      "Target_Char: lot, Response: LOL\n",
      "Entropy: 3.7680, Cumulative Entropy: 698.8932, Surprisal: 5.2468\n",
      "Target_Char: young, Response: young\n",
      "Entropy: 1.6491, Cumulative Entropy: 700.5423, Surprisal: 0.2243\n",
      "Target_Char: later, Response: later\n",
      "Entropy: 5.3900, Cumulative Entropy: 705.9323, Surprisal: 1.4823\n",
      "Target_Char: traveled, Response: travelled\n",
      "Entropy: 1.5575, Cumulative Entropy: 707.4898, Surprisal: 1.7945\n",
      "Target_Char: wife, Response: WINE\n",
      "Entropy: 4.0432, Cumulative Entropy: 711.5329, Surprisal: 4.9920\n",
      "Target_Char: daughters, Response: daughter\n",
      "Entropy: 4.6237, Cumulative Entropy: 716.1566, Surprisal: 1.7530\n",
      "Target_Char: wonderful, Response: wonderful\n",
      "Entropy: 1.5160, Cumulative Entropy: 717.6726, Surprisal: 0.3233\n",
      "Target_Char: could, Response: could\n",
      "Entropy: 1.5028, Cumulative Entropy: 719.1754, Surprisal: 0.2919\n",
      "Target_Char: see, Response: dog\n",
      "Entropy: 6.6948, Cumulative Entropy: 725.8702, Surprisal: 3.9007\n",
      "Target_Char: where, Response: white\n",
      "Entropy: 3.3467, Cumulative Entropy: 729.2170, Surprisal: 6.5972\n",
      "Target_Char: roots, Response: tools\n",
      "Entropy: 4.7112, Cumulative Entropy: 733.9282, Surprisal: 4.9270\n",
      "Target_Char: came, Response: came\n",
      "Entropy: 1.2179, Cumulative Entropy: 735.1461, Surprisal: 0.1912\n",
      "Target_Char: Like, Response: LIKE\n",
      "Entropy: 0.9591, Cumulative Entropy: 736.1052, Surprisal: 3.5579\n",
      "Target_Char: liked, Response: lined\n",
      "Entropy: 4.0660, Cumulative Entropy: 740.1712, Surprisal: 1.9788\n",
      "Target_Char: culture, Response: culture\n",
      "Entropy: 2.1054, Cumulative Entropy: 742.2767, Surprisal: 0.9046\n",
      "Target_Char: traveling, Response: traveling\n",
      "Entropy: 2.0967, Cumulative Entropy: 744.3734, Surprisal: 0.6240\n",
      "Target_Char: around, Response: around\n",
      "Entropy: 0.7481, Cumulative Entropy: 745.1215, Surprisal: 0.0934\n",
      "Target_Char: herself, Response: HOTEL\n",
      "Entropy: 7.0755, Cumulative Entropy: 752.1970, Surprisal: 5.4918\n",
      "Target_Char: too, Response: look\n",
      "Entropy: 3.4479, Cumulative Entropy: 755.6449, Surprisal: 4.9616\n",
      "Target_Char: What, Response: VITAL\n",
      "Entropy: 4.1978, Cumulative Entropy: 759.8427, Surprisal: 12.2670\n",
      "Target_Char: taught, Response: laughing\n",
      "Entropy: 0.6901, Cumulative Entropy: 760.5328, Surprisal: 9.3680\n",
      "Target_Char: mother, Response: mother\n",
      "Entropy: 3.3359, Cumulative Entropy: 763.8687, Surprisal: 1.1122\n",
      "Target_Char: sons, Response: SUNNY\n",
      "Entropy: 6.0613, Cumulative Entropy: 769.9300, Surprisal: 5.9684\n",
      "Target_Char: Despite, Response: Despite\n",
      "Entropy: 1.3500, Cumulative Entropy: 771.2799, Surprisal: 0.4163\n",
      "Target_Char: joy, Response: joy\n",
      "Entropy: 1.5271, Cumulative Entropy: 772.8071, Surprisal: 0.3497\n",
      "Target_Char: receiving, Response: receiving\n",
      "Entropy: 2.7391, Cumulative Entropy: 775.5462, Surprisal: 0.7453\n",
      "Target_Char: hoped, Response: hope\n",
      "Entropy: 2.7282, Cumulative Entropy: 778.2744, Surprisal: 2.6313\n",
      "Target_Char: others, Response: OTHERS\n",
      "Entropy: 2.9399, Cumulative Entropy: 781.2143, Surprisal: 2.1238\n",
      "Target_Char: repeat, Response: repeat\n",
      "Entropy: 3.1971, Cumulative Entropy: 784.4114, Surprisal: 0.7651\n",
      "Target_Char: what, Response: VITAL\n",
      "Entropy: 3.9475, Cumulative Entropy: 788.3589, Surprisal: 12.5620\n",
      "Target_Char: done, Response: done\n",
      "Entropy: 3.5405, Cumulative Entropy: 791.8994, Surprisal: 0.6604\n",
      "Target_Char: throw, Response: LOW\n",
      "Entropy: 3.3904, Cumulative Entropy: 795.2898, Surprisal: 3.7048\n",
      "Target_Char: bottles, Response: bottles\n",
      "Entropy: 4.7029, Cumulative Entropy: 799.9926, Surprisal: 1.5160\n",
      "Target_Char: messages, Response: messages\n",
      "Entropy: 1.9419, Cumulative Entropy: 801.9345, Surprisal: 0.5031\n",
      "Target_Char: Today, Response: today\n",
      "Entropy: 1.7994, Cumulative Entropy: 803.7339, Surprisal: 1.5854\n",
      "Target_Char: full, Response: Troll\n",
      "Entropy: 5.4826, Cumulative Entropy: 809.2165, Surprisal: 2.6251\n",
      "Target_Char: many, Response: many\n",
      "Entropy: 0.8299, Cumulative Entropy: 810.0463, Surprisal: 0.1252\n",
      "Target_Char: rubbish, Response: Rubbish\n",
      "Entropy: 3.2531, Cumulative Entropy: 813.2994, Surprisal: 1.4376\n",
      "Target_Char: more, Response: more\n",
      "Entropy: 3.9741, Cumulative Entropy: 817.2735, Surprisal: 1.0327\n",
      "Target_Char: shouldn, Response: shout\n",
      "Entropy: 3.6448, Cumulative Entropy: 820.9183, Surprisal: 3.9127\n",
      "Target_Char: t, Response: LARGE\n",
      "Entropy: 6.1176, Cumulative Entropy: 827.0359, Surprisal: 7.1210\n",
      "Target_Char: thrown, Response: seventh\n",
      "Entropy: 6.4322, Cumulative Entropy: 833.4680, Surprisal: 12.8824\n",
      "Target_Char: there, Response: there\n",
      "Entropy: 4.3578, Cumulative Entropy: 837.8258, Surprisal: 0.8526\n",
      "Target_Char: will, Response: VILLAGE\n",
      "Entropy: 1.6117, Cumulative Entropy: 839.4376, Surprisal: 4.7162\n",
      "Target_Char: display, Response: display\n",
      "Entropy: 1.3517, Cumulative Entropy: 840.7893, Surprisal: 0.2289\n",
      "Target_Char: until, Response: until\n",
      "Entropy: 3.0345, Cumulative Entropy: 843.8237, Surprisal: 0.4501\n",
      "Target_Char: beginning, Response: beginning\n",
      "Entropy: 0.7405, Cumulative Entropy: 844.5642, Surprisal: 0.1135\n",
      "Target_Char: May, Response: May\n",
      "Entropy: 2.8986, Cumulative Entropy: 847.4627, Surprisal: 0.8201\n",
      "Target_Char: experts, Response: expert\n",
      "Entropy: 4.1154, Cumulative Entropy: 851.5781, Surprisal: 2.4527\n",
      "Target_Char: attempt, Response: attempt\n",
      "Entropy: 0.7535, Cumulative Entropy: 852.3317, Surprisal: 0.0970\n",
      "Target_Char: decipher, Response: decipher\n",
      "Entropy: 3.7717, Cumulative Entropy: 856.1034, Surprisal: 1.0529\n",
      "Target_Char: rest, Response: tool\n",
      "Entropy: 5.1017, Cumulative Entropy: 861.2051, Surprisal: 7.2124\n",
      "Target_Char: text, Response: local\n",
      "Entropy: 1.5575, Cumulative Entropy: 862.7625, Surprisal: 11.2125\n",
      "Target_Char: clear, Response: clear\n",
      "Entropy: 3.5366, Cumulative Entropy: 866.2991, Surprisal: 0.7111\n",
      "Target_Char: happen, Response: happen\n",
      "Entropy: 1.6653, Cumulative Entropy: 867.9644, Surprisal: 0.2616\n",
      "Target_Char: hopes, Response: hopes\n",
      "Entropy: 1.1664, Cumulative Entropy: 869.1308, Surprisal: 0.1928\n",
      "Target_Char: stay, Response: stay\n",
      "Entropy: 2.2951, Cumulative Entropy: 871.4259, Surprisal: 1.0000\n",
      "Target_Char: We, Response: WAVE\n",
      "Entropy: 5.8107, Cumulative Entropy: 877.2367, Surprisal: 7.9081\n",
      "Target_Char: want, Response: WANT\n",
      "Entropy: 4.3614, Cumulative Entropy: 881.5980, Surprisal: 3.4815\n",
      "Target_Char: make, Response: MAKE\n",
      "Entropy: 3.8918, Cumulative Entropy: 885.4898, Surprisal: 1.4434\n",
      "Target_Char: few, Response: cow\n",
      "Entropy: 6.4196, Cumulative Entropy: 891.9095, Surprisal: 6.8401\n",
      "Target_Char: photos, Response: photos\n",
      "Entropy: 1.0743, Cumulative Entropy: 892.9838, Surprisal: 0.2841\n",
      "Target_Char: available, Response: available\n",
      "Entropy: 0.7606, Cumulative Entropy: 893.7444, Surprisal: 0.1560\n",
      "Target_Char: put, Response: put\n",
      "Entropy: 1.1416, Cumulative Entropy: 894.8860, Surprisal: 0.1772\n",
      "Target_Char: give, Response: give\n",
      "Entropy: 1.4200, Cumulative Entropy: 896.3060, Surprisal: 0.2817\n",
      "Target_Char: face, Response: race\n",
      "Entropy: 1.2325, Cumulative Entropy: 897.5384, Surprisal: 1.8502\n",
      "Target_Char: visitors, Response: visit\n",
      "Entropy: 4.6066, Cumulative Entropy: 902.1450, Surprisal: 3.1849\n",
      "Target_Char: can, Response: can\n",
      "Entropy: 2.2612, Cumulative Entropy: 904.4063, Surprisal: 0.4278\n",
      "Target_Char: Inky, Response: tiny\n",
      "Entropy: 2.3902, Cumulative Entropy: 906.7964, Surprisal: 7.3013\n",
      "Target_Char: Octopus, Response: octopus\n",
      "Entropy: 1.5033, Cumulative Entropy: 908.2997, Surprisal: 1.0119\n",
      "Target_Char: Escapes, Response: Escapes\n",
      "Entropy: 1.5789, Cumulative Entropy: 909.8786, Surprisal: 0.4742\n",
      "Target_Char: Aquarium, Response: Aquarium\n",
      "Entropy: 0.8354, Cumulative Entropy: 910.7140, Surprisal: 0.1375\n",
      "Target_Char: An, Response: MILITARY\n",
      "Entropy: 6.8983, Cumulative Entropy: 917.6124, Surprisal: 8.5406\n",
      "Target_Char: octopus, Response: octopus\n",
      "Entropy: 1.3016, Cumulative Entropy: 918.9140, Surprisal: 0.2613\n",
      "Target_Char: has, Response: has\n",
      "Entropy: 4.6807, Cumulative Entropy: 923.5946, Surprisal: 1.4521\n",
      "Target_Char: made, Response: made\n",
      "Entropy: 1.9567, Cumulative Entropy: 925.5513, Surprisal: 0.4656\n",
      "Target_Char: brazen, Response: BRAZIL\n",
      "Entropy: 6.6924, Cumulative Entropy: 932.2438, Surprisal: 8.5521\n",
      "Target_Char: escape, Response: escape\n",
      "Entropy: 1.1501, Cumulative Entropy: 933.3939, Surprisal: 0.3588\n",
      "Target_Char: National, Response: National\n",
      "Entropy: 1.4750, Cumulative Entropy: 934.8689, Surprisal: 0.2840\n",
      "Target_Char: New, Response: view\n",
      "Entropy: 2.4196, Cumulative Entropy: 937.2884, Surprisal: 4.4250\n",
      "Target_Char: Zealand, Response: Zealand\n",
      "Entropy: 4.1381, Cumulative Entropy: 941.4265, Surprisal: 1.1153\n",
      "Target_Char: breaking, Response: meaning\n",
      "Entropy: 2.9647, Cumulative Entropy: 944.3913, Surprisal: 5.4953\n",
      "Target_Char: its, Response: HOLD\n",
      "Entropy: 6.5516, Cumulative Entropy: 950.9429, Surprisal: 10.6164\n",
      "Target_Char: tank, Response: Latin\n",
      "Entropy: 2.4822, Cumulative Entropy: 953.4251, Surprisal: 8.6393\n",
      "Target_Char: slithering, Response: shining\n",
      "Entropy: 4.7014, Cumulative Entropy: 958.1265, Surprisal: 4.7847\n",
      "Target_Char: meter, Response: MELT\n",
      "Entropy: 6.6550, Cumulative Entropy: 964.7815, Surprisal: 5.4863\n",
      "Target_Char: drainpipe, Response: grampipe\n",
      "Entropy: 5.7731, Cumulative Entropy: 970.5546, Surprisal: 2.9760\n",
      "Target_Char: disappearing, Response: disappearing\n",
      "Entropy: 0.7222, Cumulative Entropy: 971.2768, Surprisal: 0.1059\n",
      "Target_Char: In, Response: TALL\n",
      "Entropy: 6.6121, Cumulative Entropy: 977.8889, Surprisal: 8.2924\n",
      "Target_Char: scenes, Response: scenes\n",
      "Entropy: 5.4402, Cumulative Entropy: 983.3291, Surprisal: 1.9765\n",
      "Target_Char: reminiscent, Response: COMMUNICATE\n",
      "Entropy: 7.1235, Cumulative Entropy: 990.4526, Surprisal: 4.7015\n",
      "Target_Char: Finding, Response: running\n",
      "Entropy: 4.3031, Cumulative Entropy: 994.7557, Surprisal: 5.9060\n",
      "Target_Char: Nemo, Response: NEMO\n",
      "Entropy: 5.9486, Cumulative Entropy: 1000.7043, Surprisal: 2.2561\n",
      "Target_Char: common, Response: common\n",
      "Entropy: 4.2545, Cumulative Entropy: 1004.9588, Surprisal: 1.4530\n",
      "Target_Char: dash, Response: vase\n",
      "Entropy: 6.6233, Cumulative Entropy: 1011.5821, Surprisal: 3.8267\n",
      "Target_Char: lid, Response: tea\n",
      "Entropy: 6.2276, Cumulative Entropy: 1017.8097, Surprisal: 6.5972\n",
      "Target_Char: accidentally, Response: accidentally\n",
      "Entropy: 1.7346, Cumulative Entropy: 1019.5443, Surprisal: 0.2383\n",
      "Target_Char: left, Response: light\n",
      "Entropy: 6.5871, Cumulative Entropy: 1026.1315, Surprisal: 5.4233\n",
      "Target_Char: slightly, Response: suggestly\n",
      "Entropy: 5.2400, Cumulative Entropy: 1031.3714, Surprisal: 4.3356\n",
      "Target_Char: ajar, Response: jail\n",
      "Entropy: 6.5180, Cumulative Entropy: 1037.8895, Surprisal: 7.7720\n",
      "Target_Char: Staff, Response: Start\n",
      "Entropy: 5.7209, Cumulative Entropy: 1043.6103, Surprisal: 5.0933\n",
      "Target_Char: middle, Response: minute\n",
      "Entropy: 2.2148, Cumulative Entropy: 1045.8251, Surprisal: 6.4962\n",
      "Target_Char: night, Response: signal\n",
      "Entropy: 5.4558, Cumulative Entropy: 1051.2809, Surprisal: 5.7098\n",
      "Target_Char: aquarium, Response: Aquarium\n",
      "Entropy: 2.3392, Cumulative Entropy: 1053.6202, Surprisal: 1.4424\n",
      "Target_Char: deserted, Response: describe\n",
      "Entropy: 2.9540, Cumulative Entropy: 1056.5741, Surprisal: 1.2178\n",
      "Target_Char: clambered, Response: clambered\n",
      "Entropy: 1.7026, Cumulative Entropy: 1058.2767, Surprisal: 0.2995\n",
      "Target_Char: top, Response: top\n",
      "Entropy: 2.9515, Cumulative Entropy: 1061.2282, Surprisal: 0.8539\n",
      "Target_Char: glass, Response: glass\n",
      "Entropy: 0.7483, Cumulative Entropy: 1061.9764, Surprisal: 0.1238\n",
      "Target_Char: enclosure, Response: enclosure\n",
      "Entropy: 2.2771, Cumulative Entropy: 1064.2536, Surprisal: 0.7320\n",
      "Target_Char: side, Response: side\n",
      "Entropy: 2.9450, Cumulative Entropy: 1067.1985, Surprisal: 0.7435\n",
      "Target_Char: floor, Response: root\n",
      "Entropy: 2.3801, Cumulative Entropy: 1069.5786, Surprisal: 4.5101\n",
      "Target_Char: Rob, Response: KNOB\n",
      "Entropy: 4.6086, Cumulative Entropy: 1074.1873, Surprisal: 5.9339\n",
      "Target_Char: Yarrell, Response: TARTELLI\n",
      "Entropy: 6.6261, Cumulative Entropy: 1080.8134, Surprisal: 6.7537\n",
      "Target_Char: national, Response: National\n",
      "Entropy: 2.0384, Cumulative Entropy: 1082.8518, Surprisal: 1.5713\n",
      "Target_Char: manager, Response: manager\n",
      "Entropy: 1.6493, Cumulative Entropy: 1084.5011, Surprisal: 0.4013\n",
      "Target_Char: Napier, Response: napkin\n",
      "Entropy: 1.7140, Cumulative Entropy: 1086.2151, Surprisal: 2.2892\n",
      "Target_Char: Octopuses, Response: octopuses\n",
      "Entropy: 1.5013, Cumulative Entropy: 1087.7164, Surprisal: 1.0790\n",
      "Target_Char: famous, Response: famous\n",
      "Entropy: 2.2797, Cumulative Entropy: 1089.9961, Surprisal: 0.4709\n",
      "Target_Char: artists, Response: artist\n",
      "Entropy: 1.8309, Cumulative Entropy: 1091.8270, Surprisal: 1.3107\n",
      "Target_Char: don, Response: door\n",
      "Entropy: 5.6056, Cumulative Entropy: 1097.4327, Surprisal: 2.3697\n",
      "Target_Char: unhappy, Response: unhappy\n",
      "Entropy: 0.8126, Cumulative Entropy: 1098.2453, Surprisal: 0.1572\n",
      "Target_Char: us, Response: cup\n",
      "Entropy: 4.5343, Cumulative Entropy: 1102.7796, Surprisal: 4.5167\n",
      "Target_Char: or, Response: dog\n",
      "Entropy: 6.5921, Cumulative Entropy: 1109.3717, Surprisal: 5.3009\n",
      "Target_Char: lonely, Response: lonely\n",
      "Entropy: 1.5347, Cumulative Entropy: 1110.9064, Surprisal: 0.5104\n",
      "Target_Char: octopuses, Response: octopuses\n",
      "Entropy: 0.8660, Cumulative Entropy: 1111.7724, Surprisal: 0.1582\n",
      "Target_Char: solitary, Response: solitary\n",
      "Entropy: 2.0958, Cumulative Entropy: 1113.8682, Surprisal: 0.8638\n",
      "Target_Char: creatures, Response: creatures\n",
      "Entropy: 2.2870, Cumulative Entropy: 1116.1551, Surprisal: 0.6667\n",
      "Target_Char: such, Response: SUCH\n",
      "Entropy: 5.5454, Cumulative Entropy: 1121.7005, Surprisal: 4.3442\n",
      "Target_Char: curious, Response: curious\n",
      "Entropy: 1.2618, Cumulative Entropy: 1122.9623, Surprisal: 0.4316\n",
      "Target_Char: boy, Response: boy\n",
      "Entropy: 1.9879, Cumulative Entropy: 1124.9502, Surprisal: 0.4051\n",
      "Target_Char: know, Response: know\n",
      "Entropy: 2.2138, Cumulative Entropy: 1127.1640, Surprisal: 0.8047\n",
      "Target_Char: happening, Response: happening\n",
      "Entropy: 2.4302, Cumulative Entropy: 1129.5942, Surprisal: 0.4074\n",
      "Target_Char: outside, Response: outside\n",
      "Entropy: 1.0643, Cumulative Entropy: 1130.6585, Surprisal: 0.1545\n",
      "Target_Char: That, Response: final\n",
      "Entropy: 4.0405, Cumulative Entropy: 1134.6990, Surprisal: 8.9500\n",
      "Target_Char: just, Response: just\n",
      "Entropy: 0.8206, Cumulative Entropy: 1135.5196, Surprisal: 0.1447\n",
      "Target_Char: personality, Response: personality\n",
      "Entropy: 1.3504, Cumulative Entropy: 1136.8700, Surprisal: 0.2634\n",
      "Target_Char: One, Response: one\n",
      "Entropy: 3.1154, Cumulative Entropy: 1139.9854, Surprisal: 1.7007\n",
      "Target_Char: theory, Response: Theory\n",
      "Entropy: 2.2460, Cumulative Entropy: 1142.2314, Surprisal: 1.1927\n",
      "Target_Char: slid, Response: STUD\n",
      "Entropy: 5.9133, Cumulative Entropy: 1148.1447, Surprisal: 5.6969\n",
      "Target_Char: journey, Response: journey\n",
      "Entropy: 0.7684, Cumulative Entropy: 1148.9131, Surprisal: 0.2159\n",
      "Target_Char: three, Response: three\n",
      "Entropy: 5.1112, Cumulative Entropy: 1154.0243, Surprisal: 1.6094\n",
      "Target_Char: four, Response: four\n",
      "Entropy: 6.1805, Cumulative Entropy: 1160.2048, Surprisal: 3.0844\n",
      "Target_Char: meters, Response: insects\n",
      "Entropy: 6.7110, Cumulative Entropy: 1166.9159, Surprisal: 3.6314\n",
      "Target_Char: sensing, Response: sensing\n",
      "Entropy: 3.5458, Cumulative Entropy: 1170.4617, Surprisal: 0.9183\n",
      "Target_Char: hand, Response: hand\n",
      "Entropy: 2.9630, Cumulative Entropy: 1173.4247, Surprisal: 0.4968\n",
      "Target_Char: led, Response: tea\n",
      "Entropy: 2.5119, Cumulative Entropy: 1175.9366, Surprisal: 8.0843\n",
      "Target_Char: directly, Response: directly\n",
      "Entropy: 0.9995, Cumulative Entropy: 1176.9362, Surprisal: 0.1462\n",
      "Target_Char: long, Response: long\n",
      "Entropy: 1.4046, Cumulative Entropy: 1178.3408, Surprisal: 0.2238\n",
      "Target_Char: opened, Response: opened\n",
      "Entropy: 2.7782, Cumulative Entropy: 1181.1190, Surprisal: 0.6279\n",
      "Target_Char: onto, Response: UNTO\n",
      "Entropy: 5.9139, Cumulative Entropy: 1187.0329, Surprisal: 6.4494\n",
      "Target_Char: waters, Response: Waltis\n",
      "Entropy: 3.1839, Cumulative Entropy: 1190.2167, Surprisal: 7.4553\n",
      "Target_Char: Hawke, Response: HAWK\n",
      "Entropy: 4.5430, Cumulative Entropy: 1194.7598, Surprisal: 1.1068\n",
      "Target_Char: Bay, Response: Day\n",
      "Entropy: 1.5185, Cumulative Entropy: 1196.2783, Surprisal: 5.2170\n",
      "Target_Char: east, Response: cast\n",
      "Entropy: 1.2949, Cumulative Entropy: 1197.5732, Surprisal: 4.6502\n",
      "Target_Char: coast, Response: COAST\n",
      "Entropy: 2.8242, Cumulative Entropy: 1200.3974, Surprisal: 1.3780\n",
      "Target_Char: North, Response: North\n",
      "Entropy: 4.0182, Cumulative Entropy: 1204.4156, Surprisal: 1.3897\n",
      "Target_Char: Island, Response: Island\n",
      "Entropy: 3.2080, Cumulative Entropy: 1207.6236, Surprisal: 0.8339\n",
      "Target_Char: Another, Response: another\n",
      "Entropy: 2.8154, Cumulative Entropy: 1210.4391, Surprisal: 2.1339\n",
      "Target_Char: possible, Response: possible\n",
      "Entropy: 2.1415, Cumulative Entropy: 1212.5806, Surprisal: 0.5757\n",
      "Target_Char: route, Response: route\n",
      "Entropy: 1.0011, Cumulative Entropy: 1213.5816, Surprisal: 0.2654\n",
      "Target_Char: involved, Response: involve\n",
      "Entropy: 1.9963, Cumulative Entropy: 1215.5779, Surprisal: 0.8760\n",
      "Target_Char: squeezing, Response: squeezing\n",
      "Entropy: 1.8333, Cumulative Entropy: 1217.4112, Surprisal: 0.7518\n",
      "Target_Char: an, Response: can\n",
      "Entropy: 3.9447, Cumulative Entropy: 1221.3559, Surprisal: 5.6339\n",
      "Target_Char: pipe, Response: pipe\n",
      "Entropy: 1.3457, Cumulative Entropy: 1222.7016, Surprisal: 0.2592\n",
      "Target_Char: under, Response: under\n",
      "Entropy: 0.3840, Cumulative Entropy: 1223.0856, Surprisal: 0.0442\n",
      "Target_Char: drain, Response: brain\n",
      "Entropy: 6.2664, Cumulative Entropy: 1229.3521, Surprisal: 6.5359\n",
      "Target_Char: When, Response: Village\n",
      "Entropy: 6.1736, Cumulative Entropy: 1235.5257, Surprisal: 9.4916\n",
      "Target_Char: we, Response: work\n",
      "Entropy: 5.0877, Cumulative Entropy: 1240.6134, Surprisal: 3.6118\n",
      "Target_Char: next, Response: tical\n",
      "Entropy: 3.2703, Cumulative Entropy: 1243.8837, Surprisal: 10.4149\n",
      "Target_Char: morning, Response: morning\n",
      "Entropy: 3.1178, Cumulative Entropy: 1247.0016, Surprisal: 0.7794\n",
      "Target_Char: empty, Response: empty\n",
      "Entropy: 2.4939, Cumulative Entropy: 1249.4954, Surprisal: 0.4150\n",
      "Target_Char: really, Response: really\n",
      "Entropy: 0.3811, Cumulative Entropy: 1249.8766, Surprisal: 0.0522\n",
      "Target_Char: surprised, Response: surprise\n",
      "Entropy: 1.7106, Cumulative Entropy: 1251.5872, Surprisal: 0.3042\n",
      "Target_Char: launched, Response: launched\n",
      "Entropy: 1.7348, Cumulative Entropy: 1253.3220, Surprisal: 0.8335\n",
      "Target_Char: search, Response: search\n",
      "Entropy: 2.7428, Cumulative Entropy: 1256.0647, Surprisal: 0.7066\n",
      "Target_Char: staff, Response: start\n",
      "Entropy: 4.0183, Cumulative Entropy: 1260.0830, Surprisal: 2.2794\n",
      "Target_Char: pretty, Response: pretty\n",
      "Entropy: 1.1908, Cumulative Entropy: 1261.2738, Surprisal: 0.2664\n",
      "Target_Char: sad, Response: save\n",
      "Entropy: 1.9729, Cumulative Entropy: 1263.2467, Surprisal: 5.8515\n",
      "Target_Char: always, Response: always\n",
      "Entropy: 0.3933, Cumulative Entropy: 1263.6400, Surprisal: 0.0578\n",
      "Target_Char: bit, Response: DILLY\n",
      "Entropy: 6.0833, Cumulative Entropy: 1269.7233, Surprisal: 7.4355\n",
      "Target_Char: surprise, Response: surprise\n",
      "Entropy: 2.0196, Cumulative Entropy: 1271.7429, Surprisal: 0.5810\n",
      "Target_Char: Reiss, Response: REISS\n",
      "Entropy: 5.8375, Cumulative Entropy: 1277.5804, Surprisal: 4.1739\n",
      "Target_Char: Jenkinson, Response: Jefferson\n",
      "Entropy: 4.5698, Cumulative Entropy: 1282.1502, Surprisal: 1.8640\n",
      "Target_Char: exhibits, Response: CAMPBELL\n",
      "Entropy: 4.9914, Cumulative Entropy: 1287.1416, Surprisal: 8.0332\n",
      "Target_Char: keeper, Response: keeper\n",
      "Entropy: 3.2778, Cumulative Entropy: 1290.4194, Surprisal: 0.7041\n",
      "Target_Char: absolutely, Response: absolutely\n",
      "Entropy: 1.1324, Cumulative Entropy: 1291.5518, Surprisal: 0.5797\n",
      "Target_Char: certain, Response: CERTAIN\n",
      "Entropy: 2.5134, Cumulative Entropy: 1294.0653, Surprisal: 2.2763\n",
      "Target_Char: taken, Response: launch\n",
      "Entropy: 4.1074, Cumulative Entropy: 1298.1727, Surprisal: 10.3478\n",
      "Target_Char: understand, Response: understand\n",
      "Entropy: 0.9347, Cumulative Entropy: 1299.1074, Surprisal: 0.1347\n",
      "Target_Char: behavior, Response: behavior\n",
      "Entropy: 1.5233, Cumulative Entropy: 1300.6306, Surprisal: 0.5902\n",
      "Target_Char: well, Response: VOLLEY\n",
      "Entropy: 5.1845, Cumulative Entropy: 1305.8152, Surprisal: 3.5003\n",
      "Target_Char: seen, Response: seen\n",
      "Entropy: 5.6074, Cumulative Entropy: 1311.4226, Surprisal: 2.0399\n",
      "Target_Char: boats, Response: goals\n",
      "Entropy: 5.5697, Cumulative Entropy: 1316.9923, Surprisal: 2.3490\n",
      "Target_Char: slip, Response: soup\n",
      "Entropy: 2.3684, Cumulative Entropy: 1319.3608, Surprisal: 9.4509\n",
      "Target_Char: through, Response: through\n",
      "Entropy: 0.8063, Cumulative Entropy: 1320.1671, Surprisal: 0.1048\n",
      "Target_Char: bilge, Response: bridge\n",
      "Entropy: 3.5066, Cumulative Entropy: 1323.6737, Surprisal: 9.8854\n",
      "Target_Char: pumps, Response: pumps\n",
      "Entropy: 4.1921, Cumulative Entropy: 1327.8658, Surprisal: 0.8496\n",
      "Target_Char: And, Response: ANTICIPATE\n",
      "Entropy: 7.2016, Cumulative Entropy: 1335.0673, Surprisal: 7.4263\n",
      "Target_Char: security, Response: Security\n",
      "Entropy: 2.2549, Cumulative Entropy: 1337.3222, Surprisal: 1.0784\n",
      "Target_Char: here, Response: HIDE\n",
      "Entropy: 6.3030, Cumulative Entropy: 1343.6252, Surprisal: 7.2547\n",
      "Target_Char: tight, Response: light\n",
      "Entropy: 0.5066, Cumulative Entropy: 1344.1319, Surprisal: 7.3168\n",
      "Target_Char: anyone, Response: anyone\n",
      "Entropy: 1.8967, Cumulative Entropy: 1346.0285, Surprisal: 0.3172\n",
      "Target_Char: why, Response: very\n",
      "Entropy: 4.8678, Cumulative Entropy: 1350.8963, Surprisal: 5.3585\n",
      "Target_Char: they, Response: unicyclem\n",
      "Entropy: 5.6376, Cumulative Entropy: 1356.5339, Surprisal: 5.8742\n",
      "Target_Char: Because, Response: Because\n",
      "Entropy: 1.0921, Cumulative Entropy: 1357.6260, Surprisal: 0.2452\n",
      "Target_Char: no, Response: HAPPY\n",
      "Entropy: 6.4230, Cumulative Entropy: 1364.0490, Surprisal: 5.3443\n",
      "Target_Char: bones, Response: bones\n",
      "Entropy: 4.6613, Cumulative Entropy: 1368.7103, Surprisal: 1.4485\n",
      "Target_Char: able, Response: able\n",
      "Entropy: 1.1698, Cumulative Entropy: 1369.8800, Surprisal: 0.1782\n",
      "Target_Char: fit, Response: ILLNESS\n",
      "Entropy: 5.7854, Cumulative Entropy: 1375.6655, Surprisal: 7.8911\n",
      "Target_Char: small, Response: small\n",
      "Entropy: 1.2174, Cumulative Entropy: 1376.8828, Surprisal: 0.1728\n",
      "Target_Char: spaces, Response: spaces\n",
      "Entropy: 1.5768, Cumulative Entropy: 1378.4596, Surprisal: 0.3094\n",
      "Target_Char: filmed, Response: human\n",
      "Entropy: 6.9286, Cumulative Entropy: 1385.3882, Surprisal: 10.5102\n",
      "Target_Char: gaps, Response: gap\n",
      "Entropy: 4.7840, Cumulative Entropy: 1390.1721, Surprisal: 2.1505\n",
      "Target_Char: size, Response: size\n",
      "Entropy: 3.3255, Cumulative Entropy: 1393.4976, Surprisal: 0.9327\n",
      "Target_Char: coins, Response: COMICS\n",
      "Entropy: 4.6571, Cumulative Entropy: 1398.1547, Surprisal: 4.0101\n",
      "Target_Char: They, Response: money\n",
      "Entropy: 5.5375, Cumulative Entropy: 1403.6922, Surprisal: 7.0205\n",
      "Target_Char: understood, Response: understood\n",
      "Entropy: 0.5436, Cumulative Entropy: 1404.2358, Surprisal: 0.0690\n",
      "Target_Char: intelligent, Response: intelligent\n",
      "Entropy: 1.6315, Cumulative Entropy: 1405.8673, Surprisal: 0.3726\n",
      "Target_Char: capable, Response: capable\n",
      "Entropy: 3.0046, Cumulative Entropy: 1408.8720, Surprisal: 0.5751\n",
      "Target_Char: using, Response: using\n",
      "Entropy: 0.5376, Cumulative Entropy: 1409.4096, Surprisal: 0.0617\n",
      "Target_Char: tools, Response: tools\n",
      "Entropy: 5.8961, Cumulative Entropy: 1415.3056, Surprisal: 2.2327\n",
      "Target_Char: At, Response: HAT\n",
      "Entropy: 7.1478, Cumulative Entropy: 1422.4535, Surprisal: 9.0981\n",
      "Target_Char: Marine, Response: manic\n",
      "Entropy: 5.1880, Cumulative Entropy: 1427.6415, Surprisal: 3.0404\n",
      "Target_Char: Education, Response: Education\n",
      "Entropy: 0.6328, Cumulative Entropy: 1428.2742, Surprisal: 0.0921\n",
      "Target_Char: Center, Response: center\n",
      "Entropy: 3.1402, Cumulative Entropy: 1431.4144, Surprisal: 2.4825\n",
      "Target_Char: Wellington, Response: Wellington\n",
      "Entropy: 1.9908, Cumulative Entropy: 1433.4052, Surprisal: 0.4987\n",
      "Target_Char: habit, Response: habit\n",
      "Entropy: 5.8970, Cumulative Entropy: 1439.3021, Surprisal: 1.7794\n",
      "Target_Char: visiting, Response: visiting\n",
      "Entropy: 2.7051, Cumulative Entropy: 1442.0073, Surprisal: 0.6591\n",
      "Target_Char: another, Response: another\n",
      "Entropy: 0.6344, Cumulative Entropy: 1442.6417, Surprisal: 0.0659\n",
      "Target_Char: overnight, Response: overnight\n",
      "Entropy: 4.4430, Cumulative Entropy: 1447.0846, Surprisal: 3.0531\n",
      "Target_Char: steal, Response: steal\n",
      "Entropy: 4.1283, Cumulative Entropy: 1451.2129, Surprisal: 1.2981\n",
      "Target_Char: crabs, Response: crabs\n",
      "Entropy: 2.2087, Cumulative Entropy: 1453.4217, Surprisal: 0.3604\n",
      "Target_Char: returning, Response: returning\n",
      "Entropy: 1.9298, Cumulative Entropy: 1455.3515, Surprisal: 0.2503\n",
      "Target_Char: own, Response: OWL\n",
      "Entropy: 4.5486, Cumulative Entropy: 1459.9001, Surprisal: 5.6734\n",
      "Target_Char: center, Response: center\n",
      "Entropy: 2.7809, Cumulative Entropy: 1462.6810, Surprisal: 1.1195\n",
      "Target_Char: Ozymandias, Response: Ozymandias\n",
      "Entropy: 2.3235, Cumulative Entropy: 1465.0045, Surprisal: 0.3935\n",
      "Target_Char: thought, Response: thought\n",
      "Entropy: 0.8963, Cumulative Entropy: 1465.9008, Surprisal: 0.1595\n",
      "Target_Char: broken, Response: STORCH\n",
      "Entropy: 4.8218, Cumulative Entropy: 1470.7226, Surprisal: 9.8052\n",
      "Target_Char: record, Response: record\n",
      "Entropy: 3.1346, Cumulative Entropy: 1473.8572, Surprisal: 0.8251\n",
      "Target_Char: opening, Response: opening\n",
      "Entropy: 2.2925, Cumulative Entropy: 1476.1497, Surprisal: 0.5742\n",
      "Target_Char: jar, Response: jail\n",
      "Entropy: 3.9333, Cumulative Entropy: 1480.0830, Surprisal: 5.6684\n",
      "Target_Char: released, Response: release\n",
      "Entropy: 6.0802, Cumulative Entropy: 1486.1632, Surprisal: 3.7900\n",
      "Target_Char: brought, Response: brought\n",
      "Entropy: 2.3650, Cumulative Entropy: 1488.5282, Surprisal: 0.4335\n",
      "Target_Char: number, Response: number\n",
      "Entropy: 2.3748, Cumulative Entropy: 1490.9030, Surprisal: 0.4072\n",
      "Target_Char: ago, Response: ago\n",
      "Entropy: 3.9583, Cumulative Entropy: 1494.8613, Surprisal: 0.9954\n",
      "Target_Char: local, Response: local\n",
      "Entropy: 1.2266, Cumulative Entropy: 1496.0879, Surprisal: 0.1994\n",
      "Target_Char: him, Response: PENNY\n",
      "Entropy: 6.7743, Cumulative Entropy: 1502.8622, Surprisal: 7.9430\n",
      "Target_Char: caught, Response: caught\n",
      "Entropy: 0.9204, Cumulative Entropy: 1503.7825, Surprisal: 0.1427\n",
      "Target_Char: crayfish, Response: crayfish\n",
      "Entropy: 3.2569, Cumulative Entropy: 1507.0394, Surprisal: 0.6963\n",
      "Target_Char: pot, Response: potato\n",
      "Entropy: 1.5114, Cumulative Entropy: 1508.5508, Surprisal: 0.2756\n",
      "Target_Char: scarred, Response: scared\n",
      "Entropy: 4.2500, Cumulative Entropy: 1512.8008, Surprisal: 1.9811\n",
      "Target_Char: rough, Response: rough\n",
      "Entropy: 1.0761, Cumulative Entropy: 1513.8769, Surprisal: 0.1589\n",
      "Target_Char: looking, Response: looking\n",
      "Entropy: 2.0747, Cumulative Entropy: 1515.9516, Surprisal: 0.4846\n",
      "Target_Char: living, Response: living\n",
      "Entropy: 1.6956, Cumulative Entropy: 1517.6472, Surprisal: 0.6107\n",
      "Target_Char: reef, Response: TIE\n",
      "Entropy: 6.7597, Cumulative Entropy: 1524.4069, Surprisal: 7.1338\n",
      "Target_Char: fighting, Response: thing\n",
      "Entropy: 6.2016, Cumulative Entropy: 1530.6085, Surprisal: 6.4363\n",
      "Target_Char: fish, Response: HAPPY\n",
      "Entropy: 7.1802, Cumulative Entropy: 1537.7887, Surprisal: 6.0528\n",
      "Target_Char: wasn, Response: WASH\n",
      "Entropy: 3.1310, Cumulative Entropy: 1540.9197, Surprisal: 3.3124\n",
      "Target_Char: best, Response: best\n",
      "Entropy: 5.0420, Cumulative Entropy: 1545.9617, Surprisal: 1.6637\n",
      "Target_Char: shape, Response: shape\n",
      "Entropy: 1.3169, Cumulative Entropy: 1547.2786, Surprisal: 0.2439\n",
      "Target_Char: According, Response: according\n",
      "Entropy: 2.7781, Cumulative Entropy: 1550.0567, Surprisal: 2.1296\n",
      "Target_Char: rugby, Response: rugby\n",
      "Entropy: 1.3234, Cumulative Entropy: 1551.3801, Surprisal: 0.2673\n",
      "Target_Char: ball, Response: ball\n",
      "Entropy: 2.1289, Cumulative Entropy: 1553.5090, Surprisal: 0.7030\n",
      "Target_Char: unusually, Response: unusually\n",
      "Entropy: 1.8641, Cumulative Entropy: 1555.3732, Surprisal: 0.7683\n",
      "Target_Char: friendly, Response: memory\n",
      "Entropy: 4.5046, Cumulative Entropy: 1559.8778, Surprisal: 6.2472\n",
      "Target_Char: inquisitive, Response: inquisitive\n",
      "Entropy: 1.9873, Cumulative Entropy: 1561.8651, Surprisal: 0.6401\n",
      "Target_Char: popular, Response: popular\n",
      "Entropy: 1.8145, Cumulative Entropy: 1563.6797, Surprisal: 0.2935\n",
      "Target_Char: attraction, Response: attraction\n",
      "Entropy: 1.6969, Cumulative Entropy: 1565.3765, Surprisal: 0.3394\n",
      "Target_Char: Blotchy, Response: Ditchy\n",
      "Entropy: 6.7275, Cumulative Entropy: 1572.1040, Surprisal: 5.3400\n",
      "Target_Char: smaller, Response: smaller\n",
      "Entropy: 2.9637, Cumulative Entropy: 1575.0678, Surprisal: 0.6452\n",
      "Target_Char: than, Response: LION\n",
      "Entropy: 6.7987, Cumulative Entropy: 1581.8665, Surprisal: 5.9048\n",
      "Target_Char: plans, Response: plans\n",
      "Entropy: 2.0601, Cumulative Entropy: 1583.9266, Surprisal: 0.4484\n",
      "Target_Char: step, Response: step\n",
      "Entropy: 1.7335, Cumulative Entropy: 1585.6602, Surprisal: 0.6773\n",
      "Target_Char: up, Response: up\n",
      "Entropy: 1.4552, Cumulative Entropy: 1587.1154, Surprisal: 0.3937\n",
      "Target_Char: result, Response: result\n",
      "Entropy: 1.2302, Cumulative Entropy: 1588.3456, Surprisal: 0.2449\n",
      "Target_Char: one, Response: one\n",
      "Entropy: 3.2396, Cumulative Entropy: 1591.5853, Surprisal: 0.9779\n",
      "Target_Char: increasingly, Response: increasingly\n",
      "Entropy: 0.4593, Cumulative Entropy: 1592.0446, Surprisal: 0.0676\n",
      "Target_Char: aware, Response: aware\n",
      "Entropy: 1.6862, Cumulative Entropy: 1593.7308, Surprisal: 0.2138\n",
      "Target_Char: actually, Response: actually\n",
      "Entropy: 0.5094, Cumulative Entropy: 1594.2402, Surprisal: 0.0688\n",
      "Target_Char: do, Response: too\n",
      "Entropy: 5.3735, Cumulative Entropy: 1599.6137, Surprisal: 2.7525\n",
      "Target_Char: Although, Response: Although\n",
      "Entropy: 1.0910, Cumulative Entropy: 1600.7047, Surprisal: 0.6876\n",
      "Target_Char: actively, Response: activity\n",
      "Entropy: 2.2360, Cumulative Entropy: 1602.9407, Surprisal: 1.7092\n",
      "Target_Char: searching, Response: searching\n",
      "Entropy: 2.6909, Cumulative Entropy: 1605.6316, Surprisal: 0.5916\n",
      "Target_Char: replacement, Response: replacement\n",
      "Entropy: 1.9329, Cumulative Entropy: 1607.5645, Surprisal: 0.4808\n",
      "Target_Char: if, Response: is\n",
      "Entropy: 4.9123, Cumulative Entropy: 1612.4768, Surprisal: 7.9694\n",
      "Target_Char: might, Response: light\n",
      "Entropy: 5.7416, Cumulative Entropy: 1618.2184, Surprisal: 5.7569\n",
      "Target_Char: willing, Response: village\n",
      "Entropy: 0.9936, Cumulative Entropy: 1619.2120, Surprisal: 5.9407\n",
      "Target_Char: Japan, Response: Japan\n",
      "Entropy: 0.6498, Cumulative Entropy: 1619.8619, Surprisal: 0.1113\n",
      "Target_Char: Calls, Response: calls\n",
      "Entropy: 3.9872, Cumulative Entropy: 1623.8490, Surprisal: 4.0736\n",
      "Target_Char: Time, Response: time\n",
      "Entropy: 5.0519, Cumulative Entropy: 1628.9009, Surprisal: 3.3440\n",
      "Target_Char: Long, Response: Long\n",
      "Entropy: 3.6760, Cumulative Entropy: 1632.5769, Surprisal: 1.5199\n",
      "Target_Char: Hours, Response: hours\n",
      "Entropy: 1.2747, Cumulative Entropy: 1633.8516, Surprisal: 5.0970\n",
      "Target_Char: Work, Response: work\n",
      "Entropy: 1.6201, Cumulative Entropy: 1635.4717, Surprisal: 2.9844\n",
      "Target_Char: Culture, Response: Culture\n",
      "Entropy: 1.0860, Cumulative Entropy: 1636.5577, Surprisal: 0.2089\n",
      "Target_Char: regulation, Response: regulation\n",
      "Entropy: 0.9105, Cumulative Entropy: 1637.4682, Surprisal: 0.2486\n",
      "Target_Char: eight, Response: eight\n",
      "Entropy: 1.8207, Cumulative Entropy: 1639.2889, Surprisal: 0.6400\n",
      "Target_Char: hours, Response: hours\n",
      "Entropy: 0.8851, Cumulative Entropy: 1640.1740, Surprisal: 0.0989\n",
      "Target_Char: office, Response: office\n",
      "Entropy: 1.0476, Cumulative Entropy: 1641.2216, Surprisal: 0.2531\n",
      "Target_Char: over, Response: over\n",
      "Entropy: 2.1344, Cumulative Entropy: 1643.3560, Surprisal: 0.4707\n",
      "Target_Char: most, Response: most\n",
      "Entropy: 4.2865, Cumulative Entropy: 1647.6425, Surprisal: 1.5555\n",
      "Target_Char: important, Response: important\n",
      "Entropy: 2.4009, Cumulative Entropy: 1650.0434, Surprisal: 0.7182\n",
      "Target_Char: work, Response: work\n",
      "Entropy: 1.7871, Cumulative Entropy: 1651.8305, Surprisal: 0.5373\n",
      "Target_Char: day, Response: way\n",
      "Entropy: 3.1310, Cumulative Entropy: 1654.9615, Surprisal: 1.5035\n",
      "Target_Char: whatever, Response: whatever\n",
      "Entropy: 3.4599, Cumulative Entropy: 1658.4214, Surprisal: 1.3806\n",
      "Target_Char: wait, Response: WALL\n",
      "Entropy: 2.6055, Cumulative Entropy: 1661.0269, Surprisal: 2.2532\n",
      "Target_Char: This, Response: FIVE\n",
      "Entropy: 6.9937, Cumulative Entropy: 1668.0206, Surprisal: 8.0378\n",
      "Target_Char: point, Response: point\n",
      "Entropy: 1.7232, Cumulative Entropy: 1669.7437, Surprisal: 0.3318\n",
      "Target_Char: workers, Response: WORKERS\n",
      "Entropy: 3.0447, Cumulative Entropy: 1672.7884, Surprisal: 1.5341\n",
      "Target_Char: heading, Response: reading\n",
      "Entropy: 3.6892, Cumulative Entropy: 1676.4776, Surprisal: 2.9315\n",
      "Target_Char: Yet, Response: TCL\n",
      "Entropy: 5.1997, Cumulative Entropy: 1681.6773, Surprisal: 9.1352\n",
      "Target_Char: millions, Response: million\n",
      "Entropy: 5.0880, Cumulative Entropy: 1686.7653, Surprisal: 2.2883\n",
      "Target_Char: Japanese, Response: Japanese\n",
      "Entropy: 0.9774, Cumulative Entropy: 1687.7427, Surprisal: 0.2329\n",
      "Target_Char: employees, Response: employees\n",
      "Entropy: 0.6033, Cumulative Entropy: 1688.3460, Surprisal: 0.0941\n",
      "Target_Char: clearing, Response: cleaning\n",
      "Entropy: 2.9366, Cumulative Entropy: 1691.2826, Surprisal: 2.4239\n",
      "Target_Char: away, Response: away\n",
      "Entropy: 1.1216, Cumulative Entropy: 1692.4042, Surprisal: 0.1373\n",
      "Target_Char: their, Response: light\n",
      "Entropy: 3.7438, Cumulative Entropy: 1696.1480, Surprisal: 9.7774\n",
      "Target_Char: desks, Response: desk\n",
      "Entropy: 6.1141, Cumulative Entropy: 1702.2621, Surprisal: 3.3631\n",
      "Target_Char: being, Response: being\n",
      "Entropy: 0.8127, Cumulative Entropy: 1703.0749, Surprisal: 0.1504\n",
      "Target_Char: dinner, Response: united\n",
      "Entropy: 6.9323, Cumulative Entropy: 1710.0071, Surprisal: 5.7949\n",
      "Target_Char: enough, Response: enough\n",
      "Entropy: 1.4567, Cumulative Entropy: 1711.4638, Surprisal: 0.4643\n",
      "Target_Char: invite, Response: VILE\n",
      "Entropy: 6.0801, Cumulative Entropy: 1717.5439, Surprisal: 7.1387\n",
      "Target_Char: accusations, Response: accusations\n",
      "Entropy: 0.8832, Cumulative Entropy: 1718.4271, Surprisal: 0.1041\n",
      "Target_Char: disloyalty, Response: disloyally\n",
      "Entropy: 5.8990, Cumulative Entropy: 1724.3262, Surprisal: 1.9156\n",
      "Target_Char: company, Response: company\n",
      "Entropy: 1.5371, Cumulative Entropy: 1725.8632, Surprisal: 0.4086\n",
      "Target_Char: decades, Response: decades\n",
      "Entropy: 1.6159, Cumulative Entropy: 1727.4791, Surprisal: 0.2630\n",
      "Target_Char: giving, Response: giving\n",
      "Entropy: 3.3652, Cumulative Entropy: 1730.8443, Surprisal: 0.6252\n",
      "Target_Char: companies, Response: companies\n",
      "Entropy: 1.7949, Cumulative Entropy: 1732.6392, Surprisal: 0.3668\n",
      "Target_Char: carte, Response: carte\n",
      "Entropy: 4.3343, Cumulative Entropy: 1736.9735, Surprisal: 2.0398\n",
      "Target_Char: blanche, Response: plane\n",
      "Entropy: 3.7130, Cumulative Entropy: 1740.6865, Surprisal: 5.3189\n",
      "Target_Char: milk, Response: HAPPY\n",
      "Entropy: 6.9343, Cumulative Entropy: 1747.6208, Surprisal: 6.0747\n",
      "Target_Char: every, Response: every\n",
      "Entropy: 1.0844, Cumulative Entropy: 1748.7053, Surprisal: 0.1424\n",
      "Target_Char: last, Response: last\n",
      "Entropy: 1.8639, Cumulative Entropy: 1750.5691, Surprisal: 0.2735\n",
      "Target_Char: drop, Response: group\n",
      "Entropy: 3.0359, Cumulative Entropy: 1753.6051, Surprisal: 2.1922\n",
      "Target_Char: productivity, Response: productivity\n",
      "Entropy: 1.4091, Cumulative Entropy: 1755.0141, Surprisal: 0.3856\n",
      "Target_Char: workforce, Response: WORKFORCE\n",
      "Entropy: 2.4533, Cumulative Entropy: 1757.4674, Surprisal: 1.8068\n",
      "Target_Char: challenge, Response: challenge\n",
      "Entropy: 1.2375, Cumulative Entropy: 1758.7049, Surprisal: 0.5043\n",
      "Target_Char: ingrained, Response: ingrained\n",
      "Entropy: 3.5649, Cumulative Entropy: 1762.2698, Surprisal: 0.8961\n",
      "Target_Char: overwork, Response: OVERWORK\n",
      "Entropy: 1.9529, Cumulative Entropy: 1764.2227, Surprisal: 1.8278\n",
      "Target_Char: government, Response: government\n",
      "Entropy: 1.0758, Cumulative Entropy: 1765.2986, Surprisal: 0.2450\n",
      "Target_Char: considering, Response: considering\n",
      "Entropy: 0.7454, Cumulative Entropy: 1766.0439, Surprisal: 0.1014\n",
      "Target_Char: making, Response: meaning\n",
      "Entropy: 1.4717, Cumulative Entropy: 1767.5156, Surprisal: 6.3877\n",
      "Target_Char: legal, Response: legal\n",
      "Entropy: 0.4156, Cumulative Entropy: 1767.9313, Surprisal: 0.0756\n",
      "Target_Char: requirement, Response: requirement\n",
      "Entropy: 0.8107, Cumulative Entropy: 1768.7420, Surprisal: 0.1153\n",
      "Target_Char: least, Response: least\n",
      "Entropy: 0.4565, Cumulative Entropy: 1769.1985, Surprisal: 0.0550\n",
      "Target_Char: five, Response: live\n",
      "Entropy: 2.2939, Cumulative Entropy: 1771.4924, Surprisal: 2.7915\n",
      "Target_Char: days, Response: ways\n",
      "Entropy: 3.0650, Cumulative Entropy: 1774.5573, Surprisal: 3.4574\n",
      "Target_Char: paid, Response: pair\n",
      "Entropy: 3.0801, Cumulative Entropy: 1777.6374, Surprisal: 2.7432\n",
      "Target_Char: holiday, Response: holiday\n",
      "Entropy: 2.5348, Cumulative Entropy: 1780.1722, Surprisal: 0.7683\n",
      "Target_Char: year, Response: year\n",
      "Entropy: 0.2753, Cumulative Entropy: 1780.4475, Surprisal: 0.0386\n",
      "Target_Char: currently, Response: currently\n",
      "Entropy: 2.9932, Cumulative Entropy: 1783.4407, Surprisal: 0.7879\n",
      "Target_Char: entitled, Response: entitled\n",
      "Entropy: 4.3589, Cumulative Entropy: 1787.7996, Surprisal: 0.9614\n",
      "Target_Char: average, Response: average\n",
      "Entropy: 0.8376, Cumulative Entropy: 1788.6373, Surprisal: 0.1382\n",
      "Target_Char: only, Response: only\n",
      "Entropy: 2.9871, Cumulative Entropy: 1791.6243, Surprisal: 0.7874\n",
      "Target_Char: fewer, Response: JEWEL\n",
      "Entropy: 3.5947, Cumulative Entropy: 1795.2191, Surprisal: 10.7787\n",
      "Target_Char: global, Response: global\n",
      "Entropy: 1.9091, Cumulative Entropy: 1797.1281, Surprisal: 0.5575\n",
      "Target_Char: minimum, Response: HORSE\n",
      "Entropy: 7.3184, Cumulative Entropy: 1804.4466, Surprisal: 8.0541\n",
      "Target_Char: ten, Response: light\n",
      "Entropy: 5.5747, Cumulative Entropy: 1810.0213, Surprisal: 10.1980\n",
      "Target_Char: holidays, Response: Holidays\n",
      "Entropy: 2.9786, Cumulative Entropy: 1812.9999, Surprisal: 1.1424\n",
      "Target_Char: reality, Response: really\n",
      "Entropy: 2.4156, Cumulative Entropy: 1815.4155, Surprisal: 1.4689\n",
      "Target_Char: even, Response: event\n",
      "Entropy: 2.4307, Cumulative Entropy: 1817.8461, Surprisal: 1.4220\n",
      "Target_Char: close, Response: CLOSE\n",
      "Entropy: 1.7721, Cumulative Entropy: 1819.6182, Surprisal: 1.0770\n",
      "Target_Char: taking, Response: landing\n",
      "Entropy: 5.0219, Cumulative Entropy: 1824.6401, Surprisal: 3.0435\n",
      "Target_Char: quota, Response: quote\n",
      "Entropy: 1.8653, Cumulative Entropy: 1826.5055, Surprisal: 1.4026\n",
      "Target_Char: typically, Response: typically\n",
      "Entropy: 0.9040, Cumulative Entropy: 1827.4094, Surprisal: 0.2640\n",
      "Target_Char: nine, Response: line\n",
      "Entropy: 6.3707, Cumulative Entropy: 1833.7802, Surprisal: 2.7857\n",
      "Target_Char: entitlement, Response: enlightenment\n",
      "Entropy: 5.8399, Cumulative Entropy: 1839.6201, Surprisal: 2.8593\n",
      "Target_Char: While, Response: Village\n",
      "Entropy: 6.1703, Cumulative Entropy: 1845.7904, Surprisal: 7.3098\n",
      "Target_Char: British, Response: DISH\n",
      "Entropy: 6.3811, Cumulative Entropy: 1852.1715, Surprisal: 4.8215\n",
      "Target_Char: regard, Response: regard\n",
      "Entropy: 0.9000, Cumulative Entropy: 1853.0716, Surprisal: 0.1228\n",
      "Target_Char: week, Response: week\n",
      "Entropy: 0.9240, Cumulative Entropy: 1853.9956, Surprisal: 0.1721\n",
      "Target_Char: summer, Response: summer\n",
      "Entropy: 3.8180, Cumulative Entropy: 1857.8136, Surprisal: 1.2949\n",
      "Target_Char: inalienable, Response: indefatigable\n",
      "Entropy: 3.1014, Cumulative Entropy: 1860.9150, Surprisal: 6.3353\n",
      "Target_Char: right, Response: light\n",
      "Entropy: 3.2857, Cumulative Entropy: 1864.2008, Surprisal: 4.7526\n",
      "Target_Char: vacation, Response: vacation\n",
      "Entropy: 2.2835, Cumulative Entropy: 1866.4842, Surprisal: 0.5011\n",
      "Target_Char: height, Response: height\n",
      "Entropy: 1.3533, Cumulative Entropy: 1867.8375, Surprisal: 0.2150\n",
      "Target_Char: self, Response: SOLI\n",
      "Entropy: 5.9771, Cumulative Entropy: 1873.8146, Surprisal: 6.2857\n",
      "Target_Char: indulgence, Response: indulgence\n",
      "Entropy: 1.7075, Cumulative Entropy: 1875.5221, Surprisal: 0.6561\n",
      "Target_Char: move, Response: move\n",
      "Entropy: 2.1605, Cumulative Entropy: 1877.6826, Surprisal: 0.7190\n",
      "Target_Char: debated, Response: debate\n",
      "Entropy: 3.2722, Cumulative Entropy: 1880.9548, Surprisal: 0.6346\n",
      "Target_Char: current, Response: current\n",
      "Entropy: 2.6798, Cumulative Entropy: 1883.6346, Surprisal: 0.4429\n",
      "Target_Char: parliamentary, Response: parliamentary\n",
      "Entropy: 1.9836, Cumulative Entropy: 1885.6182, Surprisal: 0.3931\n",
      "Target_Char: session, Response: session\n",
      "Entropy: 2.5515, Cumulative Entropy: 1888.1697, Surprisal: 0.9503\n",
      "Target_Char: comes, Response: comes\n",
      "Entropy: 0.9018, Cumulative Entropy: 1889.0715, Surprisal: 0.1271\n",
      "Target_Char: started, Response: start\n",
      "Entropy: 2.8187, Cumulative Entropy: 1891.8902, Surprisal: 1.3228\n",
      "Target_Char: encouraging, Response: encouraging\n",
      "Entropy: 1.4401, Cumulative Entropy: 1893.3303, Surprisal: 0.3597\n",
      "Target_Char: nap, Response: map\n",
      "Entropy: 2.9237, Cumulative Entropy: 1896.2541, Surprisal: 2.0535\n",
      "Target_Char: job, Response: job\n",
      "Entropy: 3.1060, Cumulative Entropy: 1899.3601, Surprisal: 0.8859\n",
      "Target_Char: improve, Response: improve\n",
      "Entropy: 0.1473, Cumulative Entropy: 1899.5073, Surprisal: 0.0193\n",
      "Target_Char: performance, Response: performance\n",
      "Entropy: 1.4421, Cumulative Entropy: 1900.9494, Surprisal: 0.3411\n",
      "Target_Char: By, Response: day\n",
      "Entropy: 4.4359, Cumulative Entropy: 1905.3853, Surprisal: 4.2596\n",
      "Target_Char: end, Response: end\n",
      "Entropy: 6.7866, Cumulative Entropy: 1912.1720, Surprisal: 2.6119\n",
      "Target_Char: decade, Response: decade\n",
      "Entropy: 5.2831, Cumulative Entropy: 1917.4551, Surprisal: 1.3422\n",
      "Target_Char: passed, Response: pass\n",
      "Entropy: 3.6854, Cumulative Entropy: 1921.1404, Surprisal: 2.4612\n",
      "Target_Char: law, Response: law\n",
      "Entropy: 0.6333, Cumulative Entropy: 1921.7737, Surprisal: 0.0957\n",
      "Target_Char: push, Response: push\n",
      "Entropy: 0.9807, Cumulative Entropy: 1922.7545, Surprisal: 0.1207\n",
      "Target_Char: towards, Response: towards\n",
      "Entropy: 1.8589, Cumulative Entropy: 1924.6133, Surprisal: 0.3095\n",
      "Target_Char: following, Response: following\n",
      "Entropy: 1.6093, Cumulative Entropy: 1926.2227, Surprisal: 0.3094\n",
      "Target_Char: example, Response: example\n",
      "Entropy: 1.2920, Cumulative Entropy: 1927.5147, Surprisal: 0.2159\n",
      "Target_Char: set, Response: cat\n",
      "Entropy: 6.7768, Cumulative Entropy: 1934.2915, Surprisal: 5.3558\n",
      "Target_Char: use, Response: use\n",
      "Entropy: 0.5427, Cumulative Entropy: 1934.8342, Surprisal: 0.0866\n",
      "Target_Char: annual, Response: annual\n",
      "Entropy: 0.8124, Cumulative Entropy: 1935.6466, Surprisal: 0.1477\n",
      "Target_Char: leave, Response: leave\n",
      "Entropy: 2.2725, Cumulative Entropy: 1937.9191, Surprisal: 0.3699\n",
      "Target_Char: those, Response: those\n",
      "Entropy: 0.7239, Cumulative Entropy: 1938.6429, Surprisal: 0.1583\n",
      "Target_Char: France, Response: France\n",
      "Entropy: 2.1785, Cumulative Entropy: 1940.8214, Surprisal: 0.3310\n",
      "Target_Char: unforgiving, Response: unforgiving\n",
      "Entropy: 1.7453, Cumulative Entropy: 1942.5668, Surprisal: 0.3490\n",
      "Target_Char: may, Response: May\n",
      "Entropy: 2.2556, Cumulative Entropy: 1944.8223, Surprisal: 1.1325\n",
      "Target_Char: helped, Response: melted\n",
      "Entropy: 6.6992, Cumulative Entropy: 1951.5215, Surprisal: 4.5122\n",
      "Target_Char: turn, Response: turn\n",
      "Entropy: 4.0658, Cumulative Entropy: 1955.5874, Surprisal: 1.0488\n",
      "Target_Char: economic, Response: Economic\n",
      "Entropy: 1.8802, Cumulative Entropy: 1957.4675, Surprisal: 1.4157\n",
      "Target_Char: superpower, Response: power\n",
      "Entropy: 2.4731, Cumulative Entropy: 1959.9407, Surprisal: 1.2500\n",
      "Target_Char: corporate, Response: corporate\n",
      "Entropy: 1.2754, Cumulative Entropy: 1961.2160, Surprisal: 0.3367\n",
      "Target_Char: foot, Response: tool\n",
      "Entropy: 3.9553, Cumulative Entropy: 1965.1713, Surprisal: 6.1835\n",
      "Target_Char: soldiers, Response: soldiers\n",
      "Entropy: 3.0954, Cumulative Entropy: 1968.2667, Surprisal: 1.1087\n",
      "Target_Char: revered, Response: TELEVISION\n",
      "Entropy: 6.3536, Cumulative Entropy: 1974.6203, Surprisal: 3.9177\n",
      "Target_Char: commitment, Response: commitment\n",
      "Entropy: 4.4150, Cumulative Entropy: 1979.0353, Surprisal: 1.6479\n",
      "Target_Char: often, Response: victor\n",
      "Entropy: 7.1546, Cumulative Entropy: 1986.1899, Surprisal: 4.1534\n",
      "Target_Char: exclusion, Response: exclusion\n",
      "Entropy: 2.6845, Cumulative Entropy: 1988.8744, Surprisal: 0.6315\n",
      "Target_Char: everything, Response: everything\n",
      "Entropy: 2.5815, Cumulative Entropy: 1991.4559, Surprisal: 0.7705\n",
      "Target_Char: else, Response: close\n",
      "Entropy: 3.6679, Cumulative Entropy: 1995.1238, Surprisal: 1.5211\n",
      "Target_Char: low, Response: LOW\n",
      "Entropy: 1.5330, Cumulative Entropy: 1996.6567, Surprisal: 1.0221\n",
      "Target_Char: birth, Response: DENTAL\n",
      "Entropy: 6.8420, Cumulative Entropy: 2003.4987, Surprisal: 5.0656\n",
      "Target_Char: rate, Response: tale\n",
      "Entropy: 5.8660, Cumulative Entropy: 2009.3647, Surprisal: 3.0650\n",
      "Target_Char: predictions, Response: predictions\n",
      "Entropy: 1.5561, Cumulative Entropy: 2010.9208, Surprisal: 0.2800\n",
      "Target_Char: rapid, Response: rapia\n",
      "Entropy: 6.5152, Cumulative Entropy: 2017.4360, Surprisal: 6.6460\n",
      "Target_Char: population, Response: population\n",
      "Entropy: 1.5409, Cumulative Entropy: 2018.9769, Surprisal: 0.3253\n",
      "Target_Char: decline, Response: decline\n",
      "Entropy: 4.8089, Cumulative Entropy: 2023.7858, Surprisal: 1.2682\n",
      "Target_Char: partly, Response: party\n",
      "Entropy: 1.1556, Cumulative Entropy: 2024.9413, Surprisal: 2.9778\n",
      "Target_Char: blamed, Response: planned\n",
      "Entropy: 4.4536, Cumulative Entropy: 2029.3949, Surprisal: 4.4355\n",
      "Target_Char: lack, Response: back\n",
      "Entropy: 3.5509, Cumulative Entropy: 2032.9458, Surprisal: 1.7420\n",
      "Target_Char: couples, Response: couples\n",
      "Entropy: 3.2180, Cumulative Entropy: 2036.1638, Surprisal: 1.0154\n",
      "Target_Char: start, Response: start\n",
      "Entropy: 1.4513, Cumulative Entropy: 2037.6151, Surprisal: 0.3805\n",
      "Target_Char: families, Response: families\n",
      "Entropy: 3.7470, Cumulative Entropy: 2041.3621, Surprisal: 0.6958\n",
      "Target_Char: More, Response: more\n",
      "Entropy: 2.2862, Cumulative Entropy: 2043.6483, Surprisal: 1.7273\n",
      "Target_Char: falling, Response: laughing\n",
      "Entropy: 5.6016, Cumulative Entropy: 2049.2499, Surprisal: 7.0167\n",
      "Target_Char: ill, Response: ILLNESS\n",
      "Entropy: 3.5243, Cumulative Entropy: 2052.7741, Surprisal: 3.6544\n",
      "Target_Char: stress, Response: SIXES\n",
      "Entropy: 5.9747, Cumulative Entropy: 2058.7488, Surprisal: 7.9241\n",
      "Target_Char: worse, Response: WORSE\n",
      "Entropy: 3.4174, Cumulative Entropy: 2062.1662, Surprisal: 2.1689\n",
      "Target_Char: succumbing, Response: succumbing\n",
      "Entropy: 4.5601, Cumulative Entropy: 2066.7263, Surprisal: 1.6856\n",
      "Target_Char: karoshi, Response: Naruto\n",
      "Entropy: 4.4854, Cumulative Entropy: 2071.2118, Surprisal: 4.2811\n",
      "Target_Char: death, Response: health\n",
      "Entropy: 1.6833, Cumulative Entropy: 2072.8950, Surprisal: 2.2441\n",
      "Target_Char: studies, Response: studies\n",
      "Entropy: 2.2765, Cumulative Entropy: 2075.1716, Surprisal: 0.6699\n",
      "Target_Char: suggesting, Response: suggesting\n",
      "Entropy: 1.0187, Cumulative Entropy: 2076.1903, Surprisal: 0.2126\n",
      "Target_Char: longer, Response: longer\n",
      "Entropy: 2.9235, Cumulative Entropy: 2079.1138, Surprisal: 0.4531\n",
      "Target_Char: workshop, Response: workshop\n",
      "Entropy: 1.4600, Cumulative Entropy: 2080.5738, Surprisal: 0.6077\n",
      "Target_Char: factory, Response: factory\n",
      "Entropy: 0.7037, Cumulative Entropy: 2081.2775, Surprisal: 0.1181\n",
      "Target_Char: necessarily, Response: necessity\n",
      "Entropy: 1.2603, Cumulative Entropy: 2082.5379, Surprisal: 0.4469\n",
      "Target_Char: people, Response: people\n",
      "Entropy: 1.0879, Cumulative Entropy: 2083.6257, Surprisal: 0.1804\n",
      "Target_Char: productive, Response: productive\n",
      "Entropy: 1.6851, Cumulative Entropy: 2085.3108, Surprisal: 0.6773\n",
      "Target_Char: today, Response: today\n",
      "Entropy: 1.4223, Cumulative Entropy: 2086.7331, Surprisal: 0.2681\n",
      "Target_Char: still, Response: still\n",
      "Entropy: 1.2838, Cumulative Entropy: 2088.0169, Surprisal: 0.2789\n",
      "Target_Char: nursing, Response: nursing\n",
      "Entropy: 3.8341, Cumulative Entropy: 2091.8510, Surprisal: 0.8256\n",
      "Target_Char: collective, Response: Collective\n",
      "Entropy: 3.2139, Cumulative Entropy: 2095.0650, Surprisal: 1.9457\n",
      "Target_Char: hangover, Response: hangover\n",
      "Entropy: 0.8004, Cumulative Entropy: 2095.8653, Surprisal: 0.2058\n",
      "Target_Char: bubble, Response: bubble\n",
      "Entropy: 1.8486, Cumulative Entropy: 2097.7139, Surprisal: 0.4343\n",
      "Target_Char: About, Response: About\n",
      "Entropy: 1.5022, Cumulative Entropy: 2099.2161, Surprisal: 0.7967\n",
      "Target_Char: compared, Response: compared\n",
      "Entropy: 2.5561, Cumulative Entropy: 2101.7722, Surprisal: 0.8783\n",
      "Target_Char: US, Response: eye\n",
      "Entropy: 6.5459, Cumulative Entropy: 2108.3181, Surprisal: 9.0283\n",
      "Target_Char: according, Response: according\n",
      "Entropy: 1.3141, Cumulative Entropy: 2109.6322, Surprisal: 0.3090\n",
      "Target_Char: data, Response: vocal\n",
      "Entropy: 6.7479, Cumulative Entropy: 2116.3801, Surprisal: 4.7919\n",
      "Target_Char: spending, Response: spending\n",
      "Entropy: 2.5173, Cumulative Entropy: 2118.8974, Surprisal: 0.5506\n",
      "Target_Char: Erika, Response: Linda\n",
      "Entropy: 5.9942, Cumulative Entropy: 2124.8917, Surprisal: 4.7015\n",
      "Target_Char: Sekiguchi, Response: SINGAPORE\n",
      "Entropy: 7.1465, Cumulative Entropy: 2132.0382, Surprisal: 3.8309\n",
      "Target_Char: extreme, Response: CALCULATE\n",
      "Entropy: 5.3727, Cumulative Entropy: 2137.4109, Surprisal: 8.1529\n",
      "Target_Char: trading, Response: training\n",
      "Entropy: 1.9785, Cumulative Entropy: 2139.3894, Surprisal: 2.3120\n",
      "Target_Char: employee, Response: employee\n",
      "Entropy: 1.4355, Cumulative Entropy: 2140.8249, Surprisal: 0.3154\n",
      "Target_Char: used, Response: used\n",
      "Entropy: 1.8979, Cumulative Entropy: 2142.7228, Surprisal: 0.4052\n",
      "Target_Char: counted, Response: counted\n",
      "Entropy: 3.1245, Cumulative Entropy: 2145.8473, Surprisal: 0.9619\n",
      "Target_Char: sick, Response: SICK\n",
      "Entropy: 5.5976, Cumulative Entropy: 2151.4449, Surprisal: 4.3967\n",
      "Target_Char: Nobody, Response: Nobody\n",
      "Entropy: 2.2606, Cumulative Entropy: 2153.7055, Surprisal: 0.8658\n",
      "Target_Char: uses, Response: use\n",
      "Entropy: 6.1711, Cumulative Entropy: 2159.8767, Surprisal: 3.8214\n",
      "Target_Char: faces, Response: tracks\n",
      "Entropy: 5.8660, Cumulative Entropy: 2165.7427, Surprisal: 3.3504\n",
      "Target_Char: dilemma, Response: university\n",
      "Entropy: 7.0570, Cumulative Entropy: 2172.7997, Surprisal: 5.7278\n",
      "Target_Char: criticism, Response: criticism\n",
      "Entropy: 2.8631, Cumulative Entropy: 2175.6627, Surprisal: 0.8054\n",
      "Target_Char: leaving, Response: leaving\n",
      "Entropy: 1.3429, Cumulative Entropy: 2177.0056, Surprisal: 0.2155\n",
      "Target_Char: colleagues, Response: congratulations\n",
      "Entropy: 3.3678, Cumulative Entropy: 2180.3735, Surprisal: 2.3874\n",
      "Target_Char: lurch, Response: larch\n",
      "Entropy: 4.1090, Cumulative Entropy: 2184.4825, Surprisal: 1.7916\n",
      "Target_Char: Yuu, Response: road\n",
      "Entropy: 3.6157, Cumulative Entropy: 2188.0982, Surprisal: 8.5661\n",
      "Target_Char: Wakebe, Response: Wander\n",
      "Entropy: 3.9667, Cumulative Entropy: 2192.0649, Surprisal: 4.1841\n",
      "Target_Char: health, Response: health\n",
      "Entropy: 1.8631, Cumulative Entropy: 2193.9279, Surprisal: 0.4538\n",
      "Target_Char: ministry, Response: industry\n",
      "Entropy: 5.4618, Cumulative Entropy: 2199.3898, Surprisal: 4.7944\n",
      "Target_Char: official, Response: official\n",
      "Entropy: 2.3610, Cumulative Entropy: 2201.7507, Surprisal: 0.6209\n",
      "Target_Char: overseeing, Response: overseeing\n",
      "Entropy: 1.8232, Cumulative Entropy: 2203.5740, Surprisal: 0.2764\n",
      "Target_Char: policy, Response: policy\n",
      "Entropy: 1.9121, Cumulative Entropy: 2205.4861, Surprisal: 0.4836\n",
      "Target_Char: working, Response: WORKING\n",
      "Entropy: 2.3341, Cumulative Entropy: 2207.8202, Surprisal: 1.9648\n",
      "Target_Char: admits, Response: admits\n",
      "Entropy: 4.4970, Cumulative Entropy: 2212.3172, Surprisal: 0.9192\n",
      "Target_Char: putting, Response: pulling\n",
      "Entropy: 4.6223, Cumulative Entropy: 2216.9394, Surprisal: 2.5001\n",
      "Target_Char: overtime, Response: Overtime\n",
      "Entropy: 3.0085, Cumulative Entropy: 2219.9480, Surprisal: 2.8484\n",
      "Target_Char: month, Response: MOTION\n",
      "Entropy: 6.6943, Cumulative Entropy: 2226.6423, Surprisal: 4.7808\n",
      "Target_Char: blames, Response: blames\n",
      "Entropy: 4.3207, Cumulative Entropy: 2230.9630, Surprisal: 1.5267\n",
      "Target_Char: irresistible, Response: Incredible\n",
      "Entropy: 3.3554, Cumulative Entropy: 2234.3184, Surprisal: 3.5931\n",
      "Target_Char: pressure, Response: pressure\n",
      "Entropy: 1.4519, Cumulative Entropy: 2235.7703, Surprisal: 0.3195\n",
      "Target_Char: match, Response: match\n",
      "Entropy: 1.5860, Cumulative Entropy: 2237.3563, Surprisal: 0.2347\n",
      "Target_Char: hour, Response: hour\n",
      "Entropy: 6.5823, Cumulative Entropy: 2243.9387, Surprisal: 3.1589\n",
      "Target_Char: worker, Response: worker\n",
      "Entropy: 2.4321, Cumulative Entropy: 2246.3708, Surprisal: 0.8618\n",
      "Target_Char: vacations, Response: vacations\n",
      "Entropy: 1.5904, Cumulative Entropy: 2247.9611, Surprisal: 0.3106\n",
      "Target_Char: unfortunately, Response: unfortunately\n",
      "Entropy: 1.0615, Cumulative Entropy: 2249.0226, Surprisal: 0.2158\n",
      "Target_Char: involves, Response: involves\n",
      "Entropy: 1.4966, Cumulative Entropy: 2250.5192, Surprisal: 0.3020\n",
      "Target_Char: quite, Response: quite\n",
      "Entropy: 0.9086, Cumulative Entropy: 2251.4278, Surprisal: 0.1827\n",
      "Target_Char: volunteer, Response: Volunteer\n",
      "Entropy: 1.6835, Cumulative Entropy: 2253.1113, Surprisal: 1.0794\n",
      "Target_Char: spirit, Response: spirit\n",
      "Entropy: 0.5300, Cumulative Entropy: 2253.6413, Surprisal: 0.0824\n",
      "Entropy: 3.2567\n",
      "Cross Entropy: 2.5868\n",
      "Recognition Accuracy: 0.5145\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "ent = 0.0\n",
    "acc = 0.0\n",
    "cross_ent = 0.0\n",
    "results = []\n",
    "csv_rows = []\n",
    "json_path = \"/swdata/yin/Cui/EM/reveil/precomputed/EN/words/onestop/lower/zero_shot_en_word_lower.json\"\n",
    "csv_path = \"/swdata/yin/Cui/EM/reveil/precomputed/EN/words/onestop/lower/zero_shot_en_word_lower.csv\"\n",
    "\n",
    "for image, entry, conversations in test_dataset:\n",
    "    image_id = entry['image']\n",
    "    conversation = conversations[:2]\n",
    "    target = entry['label']\n",
    "    freq = entry['normal_freq']\n",
    "\n",
    "    result = run_qwen_2_5_vl_inference(model=model, processor=processor, conversation = conversation, target_token=target, device=\"cuda\", max_new_tokens=1024)\n",
    "    response = result['response']\n",
    "    prob_target = result['prob_target']\n",
    "    entropy = result['entropy']\n",
    "    surp = -np.log(prob_target)\n",
    "    accuracy = int(response.strip() == target.strip())\n",
    "\n",
    "    print(f\"Target_Char: {target}, Response: {result['response']}\")\n",
    "\n",
    "    ent +=  entropy\n",
    "    # cross entropy is the negative log likelihood of the target token\n",
    "    cross_ent += surp\n",
    "    print(f\"Entropy: {result['entropy']:.4f}, Cumulative Entropy: {ent:.4f}, Surprisal: {surp:.4f}\")\n",
    "    \n",
    "    # check accuracy\n",
    "    acc += accuracy\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    csv_rows.append([\n",
    "        image_id, target, freq, entropy, surp, prob_target, response, accuracy\n",
    "    ])\n",
    "\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        \"image_id\", \"target\", \"freq\", \"entropy\", \"surprisal\", \"prob_target\", \"response\", \"acc\"\n",
    "    ])\n",
    "    writer.writerows(csv_rows)\n",
    "\n",
    "print(f\"Entropy: {ent / len(test_dataset):.4f}\")\n",
    "print(f\"Cross Entropy: {cross_ent / len(test_dataset):.4f}\")\n",
    "print(f\"Recognition Accuracy: {acc / len(test_dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1477154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Entropy: 3.2567\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for entry in results:\n",
    "    entropy = entry['entropy']\n",
    "    sum += entropy\n",
    "print(f\"Average Entropy: {sum / len(results):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb10a47",
   "metadata": {},
   "source": [
    "### Unconditional Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(freqs):\n",
    "    total = sum(freqs)\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    return -sum((f / total) * np.log(f / total) for f in freqs if f > 0)\n",
    "# print(\"Entropy of letters:\", entropy([english_letter_freq[letter] for letter in english_letter_freq.keys()]))\n",
    "print(\"Unconditional Entropy:\", entropy([test_item[1]['normal_freq'] for test_item in test_dataset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43aaaf",
   "metadata": {},
   "source": [
    "# Fine Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26157de",
   "metadata": {},
   "source": [
    "## Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, Qwen2_5_VLProcessor\n",
    "\n",
    "MIN_PIXELS = 28 * 28\n",
    "MAX_PIXELS = 1280 * 28 * 28\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"models/qwen2.5-7b-instruct-reveil-en-word-lower/best\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "processor = Qwen2_5_VLProcessor.from_pretrained(\n",
    "    \"models/qwen2.5-7b-instruct-reveil-en-word-lower/best\",\n",
    "    min_pixels=MIN_PIXELS,\n",
    "    max_pixels=MAX_PIXELS\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, Qwen2_5_VLProcessor\n",
    "\n",
    "from maestro.trainer.common.utils.device import parse_device_spec\n",
    "from maestro.trainer.models.qwen_2_5_vl.loaders import format_conversation\n",
    "\n",
    "def predict_score_with_inputs(\n",
    "    model: Qwen2_5_VLForConditionalGeneration,\n",
    "    processor: Qwen2_5_VLProcessor,\n",
    "    input_ids: torch.Tensor,\n",
    "    attention_mask: torch.Tensor,\n",
    "    pixel_values: torch.Tensor,\n",
    "    image_grid_thw: torch.Tensor,\n",
    "    device: torch.device,\n",
    "    max_new_tokens: int = 1024,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Generates predictions from the Qwen2.5-VL model using both textual and visual inputs.\n",
    "\n",
    "    Args:\n",
    "        model (Qwen2_5_VLForConditionalGeneration):\n",
    "            A Qwen2.5-VL model capable of conditional text generation with visual context.\n",
    "        processor (Qwen2_5_VLProcessor):\n",
    "            Preprocessing and postprocessing utility for the Qwen2.5-VL model.\n",
    "        input_ids (torch.Tensor):\n",
    "            Tokenized input text IDs.\n",
    "        attention_mask (torch.Tensor):\n",
    "            Attention mask corresponding to the tokenized input.\n",
    "        pixel_values (torch.Tensor):\n",
    "            Preprocessed image data (pixel values) for visual inputs.\n",
    "        image_grid_thw (torch.Tensor):\n",
    "            Tensor specifying the layout or shape of the provided images.\n",
    "        device (torch.device):\n",
    "            Device on which to run inference (e.g., ``torch.device(\"cuda\")`` or ``torch.device(\"cpu\")``).\n",
    "        max_new_tokens (int):\n",
    "            Maximum number of tokens to generate.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of decoded strings corresponding to the generated sequences.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=input_ids.to(device),\n",
    "            attention_mask=attention_mask.to(device),\n",
    "            pixel_values=pixel_values.to(device),\n",
    "            image_grid_thw=image_grid_thw.to(device),\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            output_scores=True,\n",
    "            return_dict_in_generate=True,\n",
    "            do_sample=False,  # Non-greedy decoding\n",
    "        )\n",
    "        generated_ids = [\n",
    "            generated_sequence[len(input_sequence) :]\n",
    "            for input_sequence, generated_sequence in zip(input_ids, outputs.sequences)\n",
    "        ]\n",
    "        return processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False), outputs.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from typing import Optional, Tuple, Union\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from maestro.trainer.models.qwen_2_5_vl.inference import predict_with_inputs\n",
    "from maestro.trainer.models.qwen_2_5_vl.loaders import format_conversation\n",
    "from maestro.trainer.common.utils.device import parse_device_spec\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def run_qwen_2_5_vl_inference(\n",
    "    model,\n",
    "    processor,\n",
    "    conversation: Union[str, dict],\n",
    "    target_token: str = \"a\",\n",
    "    device: str = \"auto\",\n",
    "    max_new_tokens: int = 1024,\n",
    ") -> Tuple[str, Tuple[int, int]]:\n",
    "    device = parse_device_spec(device)\n",
    "    text = processor.apply_chat_template(conversation, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, _ = process_vision_info(conversation)\n",
    "\n",
    "    inputs = processor(\n",
    "        text=text,\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    responses, scores = predict_score_with_inputs(\n",
    "        **inputs,\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        device=device,\n",
    "        max_new_tokens=max_new_tokens\n",
    "    )\n",
    "    response = responses[0]\n",
    "\n",
    "    logits = scores[0][0]\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    target_token_tokenized = processor.tokenizer.tokenize(target_token) \n",
    "    target_token_id = processor.tokenizer.convert_tokens_to_ids(target_token_tokenized[0])  # a few target tokens will have multiple subtokens\n",
    "    prob_target = probs[target_token_id].item()\n",
    "\n",
    "    # Entropy of the distribution\n",
    "    entropy = -(probs * probs.log()).sum().item()\n",
    "\n",
    "    # Top-5 predictions with probabilities and logits\n",
    "    topk_probs, topk_ids = torch.topk(probs, k=5)\n",
    "    topk_tokens = [processor.tokenizer.decode([idx]).strip() for idx in topk_ids]\n",
    "    top5 = [\n",
    "        {\"token\": tok, \"prob\": prob.item(), \"logit\": logits[idx].item()}\n",
    "        for tok, prob, idx in zip(topk_tokens, topk_probs, topk_ids)\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"target\": target_token,\n",
    "        \"prob_target\": prob_target,\n",
    "        \"entropy\": entropy,\n",
    "        \"top5\": top5\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c64c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "ent = 0.0\n",
    "acc = 0.0\n",
    "cross_ent = 0.0\n",
    "results = []\n",
    "csv_rows = []\n",
    "json_path = \"/swdata/yin/Cui/EM/reveil/precomputed/EN/words/onestop/lower/finetune_en_word_lower_best.json\"\n",
    "csv_path = \"/swdata/yin/Cui/EM/reveil/precomputed/EN/words/onestop/lower/finetune_en_word_lower_best.csv\"\n",
    "\n",
    "for image, entry, conversations in test_dataset:\n",
    "    image_id = entry['image']\n",
    "    conversation = conversations[:2]\n",
    "    target = entry['label']\n",
    "    freq = entry['normal_freq']\n",
    "\n",
    "    result = run_qwen_2_5_vl_inference(model=model, processor=processor, conversation = conversation, target_token=target, device=\"cuda\", max_new_tokens=3)\n",
    "    response = result['response'].split(' ')[0]   # sometime, it prodocue multiple tokens.\n",
    "    response = response.translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "    prob_target = result['prob_target']\n",
    "    entropy = result['entropy']\n",
    "    surp = -np.log(prob_target)\n",
    "    accuracy = int(response.strip() == target.strip())\n",
    "\n",
    "    # print(f\"Target_Char: {target}, Response: {result['response']}\")\n",
    "\n",
    "    ent +=  entropy\n",
    "    # cross entropy is the negative log likelihood of the target token\n",
    "    cross_ent += surp\n",
    "    # print(f\"Entropy: {result['entropy']:.4f}, Cumulative Entropy: {ent:.4f}, Surprisal: {surp:.4f}\")\n",
    "    if accuracy == 0:\n",
    "        print(f\"Target_Char: {target}, Response: {result['response']}\")\n",
    "        print(f\"Entropy: {result['entropy']:.4f}, Cumulative Entropy: {ent:.4f}, Surprisal: {surp:.4f}\")\n",
    "    \n",
    "    # check accuracy\n",
    "    acc += accuracy\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    csv_rows.append([\n",
    "        image_id, target, freq, entropy, surp, prob_target, response, accuracy\n",
    "    ])\n",
    "\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\n",
    "        \"image_id\", \"target\", \"freq\", \"entropy\", \"surprisal\", \"prob_target\", \"response\", \"acc\"\n",
    "    ])\n",
    "    writer.writerows(csv_rows)\n",
    "\n",
    "print(f\"Entropy: {ent / len(test_dataset):.4f}\")\n",
    "print(f\"Cross Entropy: {cross_ent / len(test_dataset):.4f}\")\n",
    "print(f\"Recognition Accuracy: {acc / len(test_dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0619b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reveil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
